import cv2
import logging
import numpy as np
import threading
import re
import time
import hashlib
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Any, Optional

# Proje iÃ§i modÃ¼ller
from config import Config
from core.user_manager import UserManager

# --- LOGLAMA ---
logger = logging.getLogger("LotusAI.Security")

# face_recognition ve dlib kontrolÃ¼
FACE_REC_AVAILABLE = False
GPU_AVAILABLE = False

try:
    import face_recognition
    import dlib
    FACE_REC_AVAILABLE = True
    # dlib'in CUDA ile derlenip derlenmediÄŸini kontrol et
    GPU_AVAILABLE = dlib.DLIB_USE_CUDA
    if GPU_AVAILABLE:
        logger.info("ğŸš€ GPU DesteÄŸi (CUDA) tespit edildi. YÃ¼z tanÄ±ma GPU Ã¼zerinden Ã§alÄ±ÅŸacak.")
    else:
        logger.warning("âš ï¸ CUDA tespit edilemedi. YÃ¼z tanÄ±ma CPU (HOG) Ã¼zerinden devam edecek.")
except ImportError:
    logger.warning("âš ï¸ 'face_recognition' veya 'dlib' kÃ¼tÃ¼phanesi bulunamadÄ±. YÃ¼z tanÄ±ma devre dÄ±ÅŸÄ±.")

class SecurityManager:
    """
    LotusAI GÃ¼venlik ve Kimlik DoÄŸrulama YÃ¶neticisi (GPU Optimize EdilmiÅŸ).
    
    Yetenekler:
    - YÃ¼z TanÄ±ma: GPU (CNN) veya CPU (HOG) tabanlÄ± anlÄ±k doÄŸrulama.
    - Ses Ä°mzasÄ±: KonuÅŸmacÄ± teÅŸhisi altyapÄ±sÄ±.
    - ZiyaretÃ§i YÃ¶netimi: Biyometrik veri kaydÄ±.
    - AkÄ±llÄ± Durum Takibi: Stabilite kontrolÃ¼ ve eriÅŸim yÃ¶netimi.
    """
    
    def __init__(self, camera_manager, memory_manager=None):
        self.camera_manager = camera_manager
        self.memory = memory_manager
        self.user_manager = UserManager()
        self.lock = threading.Lock()
        
        # Bellekte tutulan kimlik verileri
        self.known_face_encodings = []
        self.known_face_names = []
        self.known_voice_profiles = {} # {user_id: path}
        
        # Takip ve Stabilite AyarlarÄ±
        self.instability_counter = 0 
        self.MAX_INSTABILITY = 12 
        self.last_known_state = ("BEKLEME", None, "BAÅLATILIYOR")
        self.last_process_time = 0
        
        # Dizinler
        self.work_dir = Path(getattr(Config, "WORK_DIR", "./data"))
        self.faces_dir = self.work_dir / "faces"
        self.voices_dir = self.work_dir / "voices"
        self.faces_dir.mkdir(parents=True, exist_ok=True)
        self.voices_dir.mkdir(parents=True, exist_ok=True)

        # GPU ve Model AyarlarÄ±
        # EÄŸer GPU varsa varsayÄ±lan 'cnn', yoksa 'hog'
        default_model = 'cnn' if GPU_AVAILABLE else 'hog'
        self.model_type = getattr(Config, 'FACE_REC_MODEL', default_model)
        
        # GPU (CNN) kullanÄ±lÄ±yorsa analiz sÄ±klÄ±ÄŸÄ± artÄ±rÄ±labilir, CPU ise tasarruf modunda kalÄ±r
        self.process_interval = 0.2 if self.model_type == 'cnn' else 0.4
        self.recognition_tolerance = getattr(Config, 'FACE_TOLERANCE', 0.45) 
        
        if FACE_REC_AVAILABLE:
            logger.info(f"ğŸ›¡ï¸ GÃ¼venlik Modeli: {self.model_type.upper()} aktif.")
            self.reload_identities()

    def reload_identities(self):
        """KullanÄ±cÄ± veritabanÄ±ndaki tÃ¼m biyometrik verileri belleÄŸe yÃ¼kler."""
        with self.lock:
            self.known_face_encodings = []
            self.known_face_names = []
            self.known_voice_profiles = {}
            
            logger.info("ğŸ‘¤ Kimlik VeritabanÄ± BelleÄŸe YÃ¼kleniyor...")
            
            for user_id, user_data in self.user_manager.users.items():
                face_file = user_data.get("face_file")
                if face_file:
                    img_path = self.work_dir / face_file
                    if img_path.exists():
                        try:
                            # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
                            image = face_recognition.load_image_file(str(img_path))
                            # Encoding iÅŸlemi (BurasÄ± da GPU varsa hÄ±zlanÄ±r)
                            # num_jitters=1: Daha hÄ±zlÄ±, num_jitters=10: Daha doÄŸru
                            encodings = face_recognition.face_encodings(image, num_jitters=1)
                            if encodings:
                                self.known_face_encodings.append(encodings[0])
                                self.known_face_names.append(user_id)
                        except Exception as e:
                            logger.error(f"âŒ {user_id} yÃ¼z verisi hatasÄ±: {e}")
                
                voice_file = user_data.get("voice_file")
                if voice_file:
                    self.known_voice_profiles[user_id] = voice_file

            logger.info(f"âœ… Kimlik YÃ¼kleme TamamlandÄ±: {len(self.known_face_names)} yÃ¼z profili aktif.")

    def register_new_visitor(self, name: str, audio_data=None) -> Tuple[bool, str]:
        """AnlÄ±k kamera gÃ¶rÃ¼ntÃ¼sÃ¼yle yeni kullanÄ±cÄ± kaydeder (GPU Destekli TESPÄ°T)."""
        if not FACE_REC_AVAILABLE:
            return False, "Hata: YÃ¼z tanÄ±ma modÃ¼lÃ¼ sistemde yÃ¼klÃ¼ deÄŸil."

        clean_name = re.sub(r'[^a-zA-Z0-9_]', '', name.lower().replace(" ", "_"))
        
        if any(u.get('name').lower() == name.lower() for u in self.user_manager.users.values()):
            return False, f"Hata: '{name}' ismiyle zaten bir kullanÄ±cÄ± kayÄ±tlÄ±."

        frame = self.camera_manager.get_frame()
        if frame is None:
            return False, "Hata: Kamera gÃ¶rÃ¼ntÃ¼sÃ¼ alÄ±namadÄ±."

        # YÃ¼z Tespiti (GPU modunda cnn kullanÄ±lÄ±r)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        try:
            face_locations = face_recognition.face_locations(rgb_frame, model=self.model_type)
        except Exception as e:
            logger.error(f"YÃ¼z tespiti hatasÄ± (Model: {self.model_type}): {e}")
            face_locations = []
        
        if not face_locations:
            return False, "YÃ¼z tespit edilemedi. LÃ¼tfen kameraya daha net bakÄ±n."

        face_filename = f"{clean_name}_{int(time.time())}.jpg"
        face_path = self.faces_dir / face_filename
        cv2.imwrite(str(face_path), frame)
        
        voice_rel_path = None
        if audio_data:
            try:
                voice_filename = f"{clean_name}_{int(time.time())}.wav"
                voice_path = self.voices_dir / voice_filename
                with open(voice_path, "wb") as f:
                    f.write(audio_data.get_wav_data())
                voice_rel_path = f"voices/{voice_filename}"
            except Exception as e:
                logger.error(f"Ses kaydÄ± baÅŸarÄ±sÄ±z: {e}")

        success = self.user_manager.create_new_user(
            name=name,
            level=2,
            face_file=f"faces/{face_filename}",
            voice_file=voice_rel_path
        )

        if success:
            self.reload_identities()
            if self.memory:
                self.memory.save("SECURITY", "system", f"Yeni kullanÄ±cÄ± kaydedildi: {name}")
            return True, f"Seni sisteme kaydettim {name}. Seni artÄ±k tanÄ±yorum."
        
        return False, "Kritik Hata: KullanÄ±cÄ± veritabanÄ±na yazÄ±lamadÄ±."

    def check_static_frame(self, frame) -> Optional[Dict]:
        """Karede kayÄ±tlÄ± bir yÃ¼z olup olmadÄ±ÄŸÄ±nÄ± GPU/CPU Ã¼zerinden kontrol eder."""
        if not FACE_REC_AVAILABLE or frame is None or not self.known_face_encodings:
            return None

        try:
            # CNN (GPU) kullanÄ±lÄ±yorsa gÃ¶rÃ¼ntÃ¼yÃ¼ Ã§ok fazla kÃ¼Ã§Ã¼ltmeye gerek yok, 
            # Ã§Ã¼nkÃ¼ GPU zaten bÃ¼yÃ¼k kareleri hÄ±zlÄ± iÅŸler. HOG iÃ§in kÃ¼Ã§Ã¼ltme ÅŸart.
            scale = 0.5 if self.model_type == 'hog' else 0.8
            small_frame = cv2.resize(frame, (0, 0), fx=scale, fy=scale)
            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

            # Model tipine gÃ¶re (hog/cnn) konumlarÄ± bul
            face_locations = face_recognition.face_locations(rgb_small_frame, model=self.model_type)
            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

            for face_encoding in face_encodings:
                matches = face_recognition.compare_faces(
                    self.known_face_encodings, 
                    face_encoding, 
                    tolerance=self.recognition_tolerance
                )
                
                if True in matches:
                    face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)
                    best_match_index = np.argmin(face_distances)
                    if matches[best_match_index]:
                        user_id = self.known_face_names[best_match_index]
                        return self.user_manager.users.get(user_id)
        except Exception as e:
            logger.error(f"Kimlik doÄŸrulama sÄ±rasÄ±nda hata: {e}")
            
        return None

    def recognize_speaker(self, audio_data) -> Tuple[Optional[str], float]:
        """Ses teÅŸhisi (Placeholder)."""
        if not audio_data or not self.known_voice_profiles:
            return None, 0.0

        if hasattr(audio_data, 'frame_data') and len(audio_data.frame_data) > 4000:
            candidate_id = list(self.known_voice_profiles.keys())[0]
            return candidate_id, 0.70

        return None, 0.0

    def analyze_situation(self, audio_data=None) -> Tuple[str, Any, str]:
        """AnlÄ±k gÃ¼venlik durum analizi."""
        current_time = time.time()
        
        if (current_time - self.last_process_time) < self.process_interval:
            return self.last_known_state

        self.last_process_time = current_time

        if not FACE_REC_AVAILABLE:
            admin = self.user_manager.get_user_by_level(5) or {"name": "Admin", "level": 5}
            return "ONAYLI", admin, "GÃœVENLÄ°_MOD (Biyometrik Yok)"

        frame = self.camera_manager.get_frame()
        identified_user = self.check_static_frame(frame)

        # 1. KayÄ±tlÄ± KullanÄ±cÄ±
        if identified_user:
            self.instability_counter = 0
            self.camera_manager.last_seen_person = identified_user.get('name')
            
            if self.last_known_state[1] != identified_user:
                logger.info(f"ğŸ›¡ï¸ EriÅŸim: {identified_user.get('name')} ({self.model_type})")
                if self.memory:
                    self.memory.save("SECURITY", "system", f"{identified_user.get('name')} algÄ±landÄ±.")
            
            self.last_known_state = ("ONAYLI", identified_user, f"GÃ–RSEL_DOGRULAMA_{self.model_type.upper()}")
            return self.last_known_state

        # 2. YabancÄ± Tespiti
        if frame is not None:
            # YabancÄ± tespiti iÃ§in hÄ±zlÄ± olmasÄ± adÄ±na HOG kullanÄ±labilir veya 
            # GPU varsa yine CNN ile devam edilir
            small = cv2.resize(frame, (0,0), fx=0.4, fy=0.4)
            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)
            if face_recognition.face_locations(rgb, model=self.model_type):
                self.instability_counter = 0
                self.camera_manager.last_seen_person = "YabancÄ±"
                self.last_known_state = ("SORGULAMA", {"name": "YabancÄ±", "level": 0}, "TANIÅMA_MODU")
                return self.last_known_state

        # 3. Sesli Onay
        if audio_data:
            user_id, confidence = self.recognize_speaker(audio_data)
            if user_id and confidence >= 0.70:
                user = self.user_manager.users.get(user_id)
                if user:
                    self.instability_counter = 0
                    self.last_known_state = ("SES_ONAYLI", user, "SESLI_KIMLIK_DOGRULAMA")
                    return self.last_known_state

        # 4. Takip ToleransÄ±
        if self.instability_counter < self.MAX_INSTABILITY:
            self.instability_counter += 1
            if self.last_known_state[0] in ["ONAYLI", "SES_ONAYLI"]:
                return self.last_known_state 

        # 5. BoÅŸ Durum
        self.camera_manager.last_seen_person = None
        self.last_known_state = ("BEKLEME", None, "KAMERA_BOÅ")
        return self.last_known_state


# import cv2
# import logging
# import numpy as np
# from pathlib import Path
# from datetime import datetime
# import time

# # Proje iÃ§i modÃ¼ller
# from config import Config
# from core.user_manager import UserManager

# # --- LOGLAMA ---
# logger = logging.getLogger("LotusAI.Security")

# # face_recognition opsiyonel kontrolÃ¼
# try:
#     import face_recognition
#     FACE_REC_AVAILABLE = True
# except ImportError:
#     FACE_REC_AVAILABLE = False
#     logger.warning("'face_recognition' kÃ¼tÃ¼phanesi bulunamadÄ±. YÃ¼z tanÄ±ma devre dÄ±ÅŸÄ±.")

# class SecurityManager:
#     """
#     LotusAI GÃ¼venlik YÃ¶neticisi.
#     Kamera gÃ¶rÃ¼ntÃ¼lerini analiz eder, yÃ¼zleri tanÄ±r ve ses imzasÄ±nÄ± kontrol eder.
#     Tespit edilen olaylarÄ± MemoryManager'a raporlar.
#     """
#     def __init__(self, camera_manager, memory_manager=None):
#         """
#         SecurityManager'Ä± baÅŸlatÄ±r.
#         """
#         self.camera_manager = camera_manager
#         self.memory = memory_manager
#         self.user_manager = UserManager()
        
#         self.known_face_encodings = []
#         self.known_face_names = []
#         self.known_voice_files = {} # {user_id: voice_file_path}
        
#         # KararsÄ±zlÄ±k ve Takip AyarlarÄ±
#         self.instability_counter = 0 
#         self.MAX_INSTABILITY = 8 # Bir nebze artÄ±rÄ±ldÄ± (daha stabil takip iÃ§in)
#         self.last_known_state = ("BEKLEME", None, "KAMERA_YOK")
#         self.last_process_time = 0
#         self.process_interval = 0.5 # Saniyede en fazla 2 kez yÃ¼z analizi yap (CPU dostu)
        
#         # Dizin YapÄ±landÄ±rmasÄ±
#         self.faces_dir = Config.WORK_DIR / "faces"
#         self.voices_dir = Config.WORK_DIR / "voices"

#         self.faces_dir.mkdir(parents=True, exist_ok=True)
#         self.voices_dir.mkdir(parents=True, exist_ok=True)

#         self.model_type = getattr(Config, 'FACE_REC_MODEL', 'hog')
#         self.recognition_tolerance = getattr(Config, 'FACE_TOLERANCE', 0.50) # DÃ¼ÅŸÃ¼k deÄŸer = daha katÄ± tanÄ±ma
        
#         if FACE_REC_AVAILABLE:
#             self._load_identities()

#     def _load_identities(self):
#         """KayÄ±tlÄ± kullanÄ±cÄ±larÄ±n yÃ¼z ve ses verilerini belleÄŸe yÃ¼kler."""
#         self.known_face_encodings = []
#         self.known_face_names = []
#         self.known_voice_files = {}
        
#         logger.info("ğŸ‘¤ Kimlik VeritabanÄ± YÃ¼kleniyor...")
        
#         for user_id, user_data in self.user_manager.users.items():
#             # 1. YÃ¼z Verisi YÃ¼kleme
#             raw_face_path = user_data.get("face_file")
#             if raw_face_path:
#                 img_path = Config.WORK_DIR / raw_face_path
                
#                 if img_path.exists():
#                     try:
#                         img = face_recognition.load_image_file(str(img_path))
#                         # Birden fazla yÃ¼z varsa ilkini al
#                         encodings = face_recognition.face_encodings(img)
#                         if encodings:
#                             self.known_face_encodings.append(encodings[0])
#                             self.known_face_names.append(user_id)
#                     except Exception as e:
#                         logger.error(f"{user_data.get('name', user_id)} yÃ¼z verisi yÃ¼klenemedi: {e}")
            
#             # 2. Ses DosyasÄ± YÃ¼kleme
#             raw_voice_path = user_data.get("voice_file")
#             if raw_voice_path:
#                 voice_path = Config.WORK_DIR / raw_voice_path
#                 if voice_path.exists():
#                     self.known_voice_files[user_id] = str(voice_path)

#         logger.info(f"âœ… Kimlik yÃ¼kleme tamamlandÄ±: {len(self.known_face_names)} yÃ¼z, {len(self.known_voice_files)} ses profili.")

#     def register_new_visitor(self, name, audio_data=None):
#         """Yeni bir ziyaretÃ§iyi kamera ve ses verisiyle sisteme kaydeder."""
#         clean_name = "".join([c for c in name.lower().replace(" ", "_") if c.isalnum() or c == "_"])
        
#         # 1. GÃ¶rsel KayÄ±t
#         frame = self.camera_manager.get_frame()
#         face_rel_path = None
        
#         if frame is not None and FACE_REC_AVAILABLE:
#             rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
#             boxes = face_recognition.face_locations(rgb, model=self.model_type)
            
#             if boxes:
#                 face_filename = f"{clean_name}_{int(datetime.now().timestamp())}.jpg"
#                 face_full_path = self.faces_dir / face_filename
#                 cv2.imwrite(str(face_full_path), frame)
                
#                 face_rel_path = f"faces/{face_filename}"
                
#                 # Ã‡alÄ±ÅŸma anÄ±nda belleÄŸi gÃ¼ncelle
#                 encodings = face_recognition.face_encodings(rgb, boxes)
#                 if encodings:
#                     self.known_face_encodings.append(encodings[0])
#                     self.known_face_names.append(clean_name)
#                     logger.info(f"New face encoding added for {clean_name}")
#             else:
#                 return False, "YÃ¼zÃ¼nÃ¼zÃ¼ tam gÃ¶remiyorum, lÃ¼tfen kameraya biraz daha yaklaÅŸÄ±n."
#         else:
#             return False, "Kamera veya yÃ¼z tanÄ±ma modÃ¼lÃ¼ ÅŸu an aktif deÄŸil."

#         # 2. Ses KaydÄ±
#         voice_rel_path = None
#         if audio_data:
#             try:
#                 voice_filename = f"{clean_name}.wav"
#                 voice_full_path = self.voices_dir / voice_filename
#                 with open(voice_full_path, "wb") as f:
#                     f.write(audio_data.get_wav_data())
#                 voice_rel_path = f"voices/{voice_filename}"
#                 self.known_voice_files[clean_name] = str(voice_full_path)
#             except Exception as e:
#                 logger.error(f"Ses kayÄ±t hatasÄ±: {e}")

#         # 3. VeritabanÄ± ve HafÄ±za KaydÄ±
#         self.user_manager.create_new_user(
#             name=name, 
#             level=2, # Standart Misafir Seviyesi
#             face_file=face_rel_path, 
#             voice_file=voice_rel_path
#         )
        
#         if self.memory:
#             self.memory.save("SECURITY", "system", f"Sisteme yeni bir kullanÄ±cÄ± eklendi: {name}")
        
#         return True, f"Memnun oldum {name}, artÄ±k seni tanÄ±yorum."

#     def check_static_frame(self, frame):
#         """Verilen kare Ã¼zerinden kimlik tespiti yapar."""
#         if not FACE_REC_AVAILABLE or frame is None or not self.known_face_encodings:
#             return None

#         try:
#             # Performans iÃ§in: GÃ¶rÃ¼ntÃ¼ boyutunu kÃ¼Ã§Ã¼lt (HÄ±zÄ± 4 kat artÄ±rÄ±r)
#             small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
#             rgb = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
            
#             # YÃ¼z tespiti
#             face_locations = face_recognition.face_locations(rgb, model=self.model_type)
#             face_encodings = face_recognition.face_encodings(rgb, face_locations)
            
#             for face_encoding in face_encodings:
#                 # Bilinen yÃ¼zlerle karÅŸÄ±laÅŸtÄ±r
#                 matches = face_recognition.compare_faces(
#                     self.known_face_encodings, 
#                     face_encoding, 
#                     tolerance=self.recognition_tolerance
#                 )
                
#                 if True in matches:
#                     # En yakÄ±n eÅŸleÅŸmeyi bul (Euclidean distance)
#                     face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)
#                     best_match_index = np.argmin(face_distances)
                    
#                     if matches[best_match_index]:
#                         user_id = self.known_face_names[best_match_index]
#                         return self.user_manager.users.get(user_id)
                        
#         except Exception as e:
#             logger.error(f"YÃ¼z tanÄ±ma motoru hatasÄ±: {e}")
            
#         return None

#     def recognize_speaker(self, audio_data):
#         """
#         Ses verisi Ã¼zerinden konuÅŸanÄ± teÅŸhis eder.
#         Åu anlÄ±k temel uzunluk ve yapÄ± kontrolÃ¼ yapar, 
#         gelecekte tam spektral analiz iÃ§in geliÅŸtirilmeye hazÄ±rdÄ±r.
#         """
#         if not audio_data or not self.known_voice_files:
#             return None, 0.0

#         # Ä°leride: librosa.feature.mfcc karÅŸÄ±laÅŸtÄ±rmasÄ± eklenecek.
#         # Temel mantÄ±k: Ses verisi varsa ve sistemde kayÄ±tlÄ± sesler varsa
#         # mevcut akÄ±ÅŸÄ±n bozulmamasÄ± iÃ§in gÃ¼venli bir skor dÃ¶ner.
#         if hasattr(audio_data, 'frame_data') and len(audio_data.frame_data) > 3000:
#             # Åimdilik kayÄ±tlÄ± ilk kullanÄ±cÄ±yÄ± simÃ¼le ediyor (GeliÅŸtirilecek)
#             candidate_id = list(self.known_voice_files.keys())[0]
#             return candidate_id, 0.85 
        
#         return None, 0.0

#     def analyze_situation(self, audio_data=None):
#         """
#         Sistemin o anki gÃ¼venlik durumunu analiz eder. 
#         Kamera ve ses verilerini birleÅŸtirerek 'ONAYLI', 'SORGULAMA' veya 'BEKLEME' dÃ¶ner.
#         """
#         current_time = time.time()
        
#         # CPU Tasarrufu: Ã‡ok sÄ±k analiz yapma
#         if (current_time - self.last_process_time) < self.process_interval:
#             return self.last_known_state

#         self.last_process_time = current_time

#         # YÃ¼z tanÄ±ma kapalÄ±ysa varsayÄ±lan admin onayÄ±
#         if not FACE_REC_AVAILABLE:
#             # Config'den veya UserManager'dan admini Ã§ek
#             admin = self.user_manager.get_user_by_level(5) # Seviye 5 = Admin
#             if not admin: # Fallback
#                  admin = {"name": "Admin", "level": 5}
#             return "ONAYLI", admin, "GÃœVENLÄ°_MOD (YÃ¼z TanÄ±ma Devre DÄ±ÅŸÄ±)"

#         frame = self.camera_manager.get_frame()
        
#         # 1. GÃ–RSEL ANALÄ°Z
#         identified_user = self.check_static_frame(frame)
        
#         if identified_user:
#             self.instability_counter = 0
#             self.camera_manager.last_seen_person = identified_user.get('name')
            
#             # Durum DeÄŸiÅŸikliÄŸi Logu
#             if self.last_known_state[1] != identified_user:
#                 logger.info(f"ğŸ›¡ï¸ EriÅŸim Yetkisi OnaylandÄ±: {identified_user.get('name')}")
#                 if self.memory:
#                     self.memory.save("SECURITY", "system", f"{identified_user.get('name')} tespit edildi ve eriÅŸim saÄŸlandÄ±.")
            
#             self.last_known_state = ("ONAYLI", identified_user, None)
#             return self.last_known_state

#         # 2. YABANCI TESPÄ°TÄ° (YÃ¼z var ama tanÄ±nmÄ±yor)
#         if frame is not None:
#             rgb = cv2.cvtColor(cv2.resize(frame, (0,0), fx=0.5, fy=0.5), cv2.COLOR_BGR2RGB)
#             if face_recognition.face_locations(rgb, model=self.model_type):
#                 self.instability_counter = 0
#                 self.camera_manager.last_seen_person = "YabancÄ±"
#                 self.last_known_state = ("SORGULAMA", {"name": "YabancÄ±", "level": 0}, "TANIÅMA_MODU")
#                 return self.last_known_state

#         # 3. SES Ä°LE DOÄRULAMA (GÃ¶rÃ¼ntÃ¼ net deÄŸilse veya kiÅŸi karanlÄ±ktaysa)
#         if audio_data:
#             v_user_id, confidence = self.recognize_speaker(audio_data)
#             if v_user_id and confidence > 0.80:
#                 user = self.user_manager.users.get(v_user_id)
#                 if user:
#                     self.instability_counter = 0
#                     logger.info(f"ğŸ¤ Ses Ä°mzasÄ± ile GiriÅŸ: {user.get('name')}")
#                     self.last_known_state = ("SES_ONAYLI", user, "GÃ–RÃœNTÃœ_YOK_SES_VAR")
#                     return self.last_known_state

#         # 4. KARARSIZLIK KONTROLÃœ
#         # KiÅŸi anlÄ±k olarak kafasÄ±nÄ± Ã§evirmiÅŸ veya Ä±ÅŸÄ±k patlamÄ±ÅŸ olabilir.
#         # Hemen 'BEKLEME'ye dÃ¼ÅŸmemek iÃ§in birkaÃ§ frame daha tolerans tanÄ±yoruz.
#         if self.instability_counter < self.MAX_INSTABILITY:
#             self.instability_counter += 1
#             if self.last_known_state[0] in ["ONAYLI", "SES_ONAYLI"]:
#                 return self.last_known_state 
        
#         # 5. KÄ°MSE YOK
#         self.camera_manager.last_seen_person = None
#         self.last_known_state = ("BEKLEME", None, "KAMERA_YOK")
#         return self.last_known_state
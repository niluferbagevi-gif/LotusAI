import re
import logging
import threading
from collections import Counter
from typing import Dict, List, Any, Optional

# --- YAPILANDIRMA VE FALLBACK ---
try:
    from config import Config
except ImportError:
    class Config:
        USE_GPU = False

# --- LOGLAMA ---
logger = logging.getLogger("LotusAI.NLP")

# --- KÃœTÃœPHANE VE GPU KONTROLÃœ ---
NLP_AVAILABLE = False
HAS_GPU = False
DEVICE_ID = -1  # -1: CPU, 0: GPU (CUDA)
DEVICE_NAME = "CPU"

try:
    import torch
    from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
    NLP_AVAILABLE = True
except ImportError as e:
    logger.warning(f"âš ï¸ NLP kÃ¼tÃ¼phaneleri eksik: {e}. (pip install torch transformers)")

# Config Ã¼zerinden GPU kontrolÃ¼
USE_GPU_CONFIG = getattr(Config, "USE_GPU", False)

if NLP_AVAILABLE and USE_GPU_CONFIG:
    try:
        if torch.cuda.is_available():
            HAS_GPU = True
            DEVICE_ID = 0
            DEVICE_NAME = "GPU (CUDA)"
            try:
                gpu_name = torch.cuda.get_device_name(0)
                logger.info(f"ğŸš€ NLP ModÃ¼lÃ¼ GPU Aktif: {gpu_name}")
            except:
                logger.info("ğŸš€ NLP ModÃ¼lÃ¼ GPU Aktif")
        else:
            logger.info("â„¹ï¸ NLP: Config GPU aÃ§Ä±k ancak donanÄ±m bulunamadÄ±. CPU kullanÄ±lacak.")
    except Exception as e:
        logger.warning(f"âš ï¸ NLP GPU kontrol hatasÄ±: {e}")
else:
    if NLP_AVAILABLE:
        logger.info("â„¹ï¸ NLP iÅŸlemleri CPU modunda (Config ayarÄ±).")


class NLPManager:
    """
    LotusAI DoÄŸal Dil Ä°ÅŸleme (NLP) ve Duygu Analizi YÃ¶neticisi.
    
    Yetenekler:
    - GPU HÄ±zlandÄ±rma: Transformer modelleri CUDA Ã¼zerinden Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r (Config kontrollÃ¼).
    - Derin Ã–ÄŸrenme TabanlÄ± Duygu Analizi: TÃ¼rkÃ§e BERT modeli ile yÃ¼ksek doÄŸruluk.
    - AkÄ±llÄ± Temizleme: Metni gÃ¼rÃ¼ltÃ¼den ve dolgu kelimelerinden arÄ±ndÄ±rÄ±r.
    - Veri AyÄ±klama: Rezervasyon ve iletiÅŸim bilgilerini Regex ile Ã§eker.
    """
    
    def __init__(self):
        # Ã‡oklu thread eriÅŸimi iÃ§in kilit
        self.lock = threading.RLock()
        
        self.sentiment_pipeline = None
        
        if NLP_AVAILABLE:
            # Model ve Tokenizer YÃ¼kleme (TÃ¼rkÃ§e Duygu Analizi iÃ§in BERT tabanlÄ± model)
            try:
                model_name = "savasy/bert-base-turkish-sentiment-cased"
                self.sentiment_pipeline = pipeline(
                    "sentiment-analysis", 
                    model=model_name, 
                    tokenizer=model_name, 
                    device=DEVICE_ID
                )
                logger.info(f"âœ… NLP Modeli {DEVICE_NAME} Ã¼zerinde yÃ¼klendi.")
            except Exception as e:
                logger.error(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
        else:
            logger.warning("âš ï¸ NLP modÃ¼lleri eksik olduÄŸu iÃ§in duygu analizi pasif.")

        # Stop Words (Analiz dÄ±ÅŸÄ± bÄ±rakÄ±lacak etkisiz kelimeler)
        self.stop_words = {
            "ve", "ile", "ama", "fakat", "lakin", "ancak", "de", "da", "ki", "bu", "ÅŸu", "o",
            "bir", "daha", "en", "Ã§ok", "mi", "mÄ±", "mu", "mÃ¼", "ben", "sen", "biz", "siz",
            "iÃ§in", "gibi", "kadar", "diye", "yok", "var", "ne", "neden", "nasÄ±l", "mÄ±dÄ±r"
        }
        
        # SayÄ±sal karÅŸÄ±lÄ±klar (Rezervasyon ayÄ±klama iÃ§in)
        self.word_to_num = {
            "bir": 1, "iki": 2, "Ã¼Ã§": 3, "dÃ¶rt": 4, "beÅŸ": 5, 
            "altÄ±": 6, "yedi": 7, "sekiz": 8, "dokuz": 9, "on": 10
        }

    def turkish_lower(self, text: str) -> str:
        """TÃ¼rkÃ§e karakterlere duyarlÄ± kÃ¼Ã§Ã¼k harfe Ã§evirme."""
        if not text: return ""
        map_chars = str.maketrans("IÄ°ÄÃœÅÃ–Ã‡", "Ä±iÄŸÃ¼ÅŸÃ¶Ã§")
        return text.translate(map_chars).lower()

    def clean_text(self, text: str, for_analysis: bool = False) -> str:
        """Metni gereksiz boÅŸluklardan ve dolgu kelimelerinden temizler."""
        if not text: return ""
        
        with self.lock:
            clean = self.turkish_lower(text)
            # Dolgu seslerini temizle
            clean = re.sub(r'\b(eee|mmm|hmm|ÅŸey|yani|Ä±Ä±Ä±|aa|ee|bi)\b', '', clean)
            
            if for_analysis:
                # Sadece harf ve rakamlarÄ± bÄ±rak
                clean = re.sub(r'[^\w\s]', '', clean)
                
            return " ".join(clean.split())

    def detect_emotion(self, text: str) -> str:
        """
        Derin Ã¶ÄŸrenme modeli kullanarak duygu analizi yapar.
        GPU desteÄŸi sayesinde model tahminleri Ã§ok hÄ±zlÄ± gerÃ§ekleÅŸir.
        """
        if not self.sentiment_pipeline or not text:
            return "NOTR"

        with self.lock:
            try:
                # Modeli Ã§alÄ±ÅŸtÄ±r
                result = self.sentiment_pipeline(text[:512])[0] # BERT 512 token sÄ±nÄ±rÄ±
                label = result['label'].upper() # 'POSITIVE' veya 'NEGATIVE'
                score = result['score']
                
                # Skor eÅŸiÄŸi kontrolÃ¼ (DÃ¼ÅŸÃ¼k gÃ¼venilirlikte nÃ¶tr kabul et)
                if score < 0.6:
                    return "NOTR"
                
                # Model etiketlerini LotusAI formatÄ±na Ã§evir
                if "POSITIVE" in label: return "POZITIF"
                if "NEGATIVE" in label: return "NEGATIF"
                return "NOTR"
            except Exception as e:
                logger.error(f"Duygu analizi hatasÄ±: {e}")
                return "NOTR"

    def analyze_batch(self, text_list: List[str]) -> Dict[str, Any]:
        """
        Yorum listesi Ã¼zerinde TOPLU (Batch) analiz yapar.
        GPU Ã¼zerinde toplu iÅŸleme performansÄ± maksimize eder.
        """
        if not text_list or not self.sentiment_pipeline:
            return {"status": "Veri Yok"}

        with self.lock:
            results = {
                "positive": 0, "negative": 0, "neutral": 0,
                "all_text": "", "neg_text": ""
            }

            # GPU avantajÄ±nÄ± kullanmak iÃ§in listeyi toplu olarak modele gÃ¶nderiyoruz
            try:
                # BoÅŸ metinleri filtrele
                valid_texts = [t for t in text_list if t.strip()]
                model_results = self.sentiment_pipeline(valid_texts, truncation=True)
                
                for i, res in enumerate(model_results):
                    label = res['label'].upper()
                    score = res['score']
                    text = valid_texts[i]
                    cleaned = self.clean_text(text, for_analysis=True)
                    results["all_text"] += cleaned + " "
                    
                    if score < 0.6:
                        results["neutral"] += 1
                    elif "POSITIVE" in label:
                        results["positive"] += 1
                    elif "NEGATIVE" in label:
                        results["negative"] += 1
                        results["neg_text"] += cleaned + " "
                    else:
                        results["neutral"] += 1

                total = len(valid_texts)
                sentiment_score = int((results["positive"] / total) * 100) if total > 0 else 0
                
                return {
                    "total_count": total,
                    "device_used": DEVICE_NAME,
                    "sentiment_distribution": {
                        "positive": results["positive"],
                        "negative": results["negative"],
                        "neutral": results["neutral"]
                    },
                    "satisfaction_rate": f"%{sentiment_score}",
                    "top_complaints": self.extract_keywords(results["neg_text"], 3),
                    "popular_topics": self.extract_keywords(results["all_text"], 5)
                }
            except Exception as e:
                logger.error(f"Batch analiz hatasÄ±: {e}")
                return {"status": "Hata", "error": str(e)}

    def extract_keywords(self, text: str, top_n: int = 5) -> List[str]:
        """En sÄ±k geÃ§en ve anlam taÅŸÄ±yan anahtar kelimeleri bulur."""
        if not text: return []
        words = text.split()
        filtered = [w for w in words if w not in self.stop_words and len(w) > 2]
        return [item[0] for item in Counter(filtered).most_common(top_n)]

    def get_behavior_prompt(self, text: str) -> str:
        """KullanÄ±cÄ±nÄ±n moduna gÃ¶re Gemini/LLM iÃ§in davranÄ±ÅŸ talimatÄ± Ã¼retir."""
        emotion = self.detect_emotion(text)
        if emotion == "POZITIF": 
            return "[DAVRANIÅ: Enerjik, minnettar ve samimi ol. GÃ¼lÃ¼mseyen bir ton kullan.]"
        elif emotion == "NEGATIF": 
            return "[DAVRANIÅ: Alttan al, son derece nazik ve profesyonel ol. Ã‡Ã¶zÃ¼m odaklÄ± ve Ã¶zÃ¼r dileyen bir ton kullan.]"
        return "[DAVRANIÅ: Net, kÄ±sa ve ciddi bir profesyonellikle yanÄ±t ver.]"

    def extract_reservation_details(self, text: str) -> Dict[str, Any]:
        """Metinden rezervasyon verilerini (KiÅŸi, Saat, Telefon) ayÄ±klar (Regex)."""
        text = self.turkish_lower(text)
        
        with self.lock:
            # 1. KiÅŸi SayÄ±sÄ± AyÄ±klama
            count = "Bilinmiyor"
            count_match = re.search(r'(\d+)\s*(?:kiÅŸi|kisilik|tane|masa|pax)', text)
            if count_match:
                count = count_match.group(1)
            else:
                for word, val in self.word_to_num.items():
                    if f"{word} kiÅŸi" in text or f"{word} kiÅŸilik" in text:
                        count = str(val)
                        break
            
            # 2. Saat AyÄ±klama
            time_val = "Belirtilmedi"
            time_match = re.search(r'(\d{1,2})[:. ](\d{2})', text)
            if time_match:
                h, m = int(time_match.group(1)), int(time_match.group(2))
                if h < 24 and m < 60:
                    time_val = f"{str(h).zfill(2)}:{str(m).zfill(2)}"
            
            if time_val == "Belirtilmedi":
                if "akÅŸam" in text: 
                    time_val = "AkÅŸam (Saat Belirsiz)"
                    for word, val in self.word_to_num.items():
                        if f"akÅŸam {word}" in text:
                            time_val = f"{val + 12}:00" if val < 12 else f"{val}:00"
                elif "Ã¶ÄŸle" in text: time_val = "Ã–ÄŸle (Saat Belirsiz)"
                elif "yarÄ±n" in text: time_val = "YarÄ±n"
            
            # 3. Telefon NumarasÄ± AyÄ±klama
            phone = None
            phone_pattern = r'(\+?9?0?\s?5\d{2}\s?-?\d{3}\s?-?\d{2}\s?-?\d{2})'
            phone_matches = re.findall(phone_pattern, text)
            
            if phone_matches:
                raw_num = phone_matches[0]
                clean_num = re.sub(r'\D', '', raw_num)
                if clean_num.startswith("05") and len(clean_num) == 11:
                    phone = f"+90{clean_num[1:]}"
                elif clean_num.startswith("5") and len(clean_num) == 10:
                    phone = f"+90{clean_num}"
                elif clean_num.startswith("905") and len(clean_num) == 12:
                    phone = f"+{clean_num}"
                else:
                    phone = raw_num 

            return {
                "kisi_sayisi": count,
                "saat": time_val,
                "iletisim": phone,
                "ham_metin_ozeti": f"{count} kiÅŸi / {time_val}"
            }
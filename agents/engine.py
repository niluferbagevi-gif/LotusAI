"""
LotusAI Agent Engine - Multi-Agent Koordinasyon Motoru
SÃ¼rÃ¼m: 2.5.5
AÃ§Ä±klama: Agent seÃ§imi, LLM iletiÅŸimi, gÃ¶rsel analiz ve dinamik yanÄ±t Ã¼retimi
GÃ¼ncelleme: CODING_MODEL (Sidar) desteÄŸi, ajan bazlÄ± Ollama model seÃ§imi eklendi.
"""

import aiohttp
import asyncio
import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List, Any, Union, Tuple
from dataclasses import dataclass
from enum import Enum

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GOOGLE AI SDK
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    logging.warning("âš ï¸ google-generativeai yÃ¼klÃ¼ deÄŸil, Gemini devre dÄ±ÅŸÄ±")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GÃ–RÃœNTÃœ Ä°ÅLEME
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    logging.warning("âš ï¸ Pillow yÃ¼klÃ¼ deÄŸil, gÃ¶rÃ¼ntÃ¼ iÅŸleme kÄ±sÄ±tlÄ±")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    logging.warning("âš ï¸ opencv-python yÃ¼klÃ¼ deÄŸil, kamera desteÄŸi yok")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GPU DESTEÄI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORE MODÃœLLER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from config import Config

logger = logging.getLogger("LotusAI.Engine")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SABITLER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class EngineConfig:
    """Engine Ã§alÄ±ÅŸma parametreleri"""
    # Retry ayarlarÄ±
    MAX_RETRIES: int = 5
    INITIAL_BACKOFF: float = 2.0
    MAX_BACKOFF: float = 32.0

    # Timeout'lar
    OLLAMA_TIMEOUT: int = 120
    GEMINI_TIMEOUT: int = 60

    # Metin limitleri
    BIO_MAX_CHARS: int = 3000
    CONTEXT_MAX_ITEMS: int = 10

    # Dosya tipleri
    SUPPORTED_IMAGE_TYPES = {'.png', '.jpg', '.jpeg', '.webp'}
    SUPPORTED_DOC_TYPES = {'.pdf', '.txt'}

    # Prompt temalarÄ±
    WELCOME_KEYWORDS = ["selam", "merhaba", "geldim", "buradayÄ±m", "hey lotus"]
    VISUAL_TRIGGERS = ["fatura", "fiÅŸ", "dekont", "hesap", "oku", "iÅŸle",
                       "ne yazÄ±yor", "analiz et", "gÃ¶ster"]

    # SIDAR iÃ§in kod/sistem tetikleyicileri (Ollama CODING_MODEL yÃ¶nlendirmesi iÃ§in)
    SIDAR_CODE_TRIGGERS = [
        "kod", "kodla", "yaz", "hata", "debug", "terminal", "log",
        "script", "python", "fonksiyon", "class", "modÃ¼l", "dÃ¼zelt",
        "refactor", "test", "fix", "bug", "exception", "import"
    ]

    # Deterministik zaman/tarih intent regex kalÄ±plarÄ±
    # Not: Ã‡ok genel kelimeler ("gÃ¼n", "saat", "bugÃ¼n") tek baÅŸÄ±na tetikleyici deÄŸildir.
    TIME_QUERY_PATTERNS = [
        r"^(ÅŸu an )?saat( kaÃ§| nedir)?\??$",
        r"^time\??$"
    ]
    DATE_QUERY_PATTERNS = [
        r"^(bugÃ¼nÃ¼n )?tarih(i)?( ne| nedir)?\??$",
        r"^bugÃ¼n tarih (ne|nedir)\??$",
        r"^date\??$"
    ]
    DAY_QUERY_PATTERNS = [
        r"^(bugÃ¼n )?(gÃ¼nlerden )?hangi gÃ¼n\??$",
        r"^bugÃ¼n gÃ¼nlerden ne\??$",
        r"^weekday\??$"
    ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# YARDIMCI SINIFLAR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@dataclass
class AgentResponse:
    """Agent yanÄ±t yapÄ±sÄ±"""
    agent: str
    content: str
    metadata: Optional[Dict[str, Any]] = None


class SecurityStatus(Enum):
    """GÃ¼venlik durumlarÄ±"""
    APPROVED = "ONAYLI"
    VOICE_APPROVED = "SES_ONAYLI"
    PENDING = "BEKLEMEDE"
    DENIED = "REDDEDÄ°LDÄ°"
    NO_CAMERA = "KAMERA_YOK"
    INTRO_MODE = "TANIÅMA_MODU"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AGENT YÃ–NETÄ°CÄ°SÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class AgentLoader:
    """Agent modÃ¼llerini dinamik olarak yÃ¼kler"""

    _loaded_agents: Dict[str, Any] = {}
    _load_status: Dict[str, bool] = {}

    AGENT_MAP = {
        "ATLAS": ("atlas", "AtlasAgent"),
        "GAYA": ("gaya", "GayaAgent"),
        "POYRAZ": ("poyraz", "PoyrazAgent"),
        "KURT": ("kurt", "KurtAgent"),
        "SIDAR": ("sidar", "SidarAgent"),
        "KERBEROS": ("kerberos", "KerberosAgent")
    }

    @classmethod
    def load_agent(cls, agent_name: str) -> Optional[type]:
        """
        Agent class'Ä±nÄ± yÃ¼kle

        Args:
            agent_name: Agent adÄ± (ATLAS, GAYA, vb.)

        Returns:
            Agent class veya None
        """
        if agent_name in cls._loaded_agents:
            return cls._loaded_agents[agent_name]

        if agent_name not in cls.AGENT_MAP:
            logger.warning(f"Bilinmeyen agent: {agent_name}")
            return None

        module_name, class_name = cls.AGENT_MAP[agent_name]

        try:
            module = __import__(f"agents.{module_name}", fromlist=[class_name])
            agent_class = getattr(module, class_name)

            cls._loaded_agents[agent_name] = agent_class
            cls._load_status[agent_name] = True
            logger.info(f"âœ… {agent_name} agent yÃ¼klendi")

            return agent_class

        except (ImportError, AttributeError) as e:
            logger.debug(f"Agent yÃ¼klenemedi ({agent_name}): {e}")
            cls._load_status[agent_name] = False
            return None

    @classmethod
    def load_all(cls) -> Dict[str, bool]:
        """TÃ¼m agent'larÄ± yÃ¼kle ve durum dÃ¶ndÃ¼r"""
        for agent_name in cls.AGENT_MAP.keys():
            cls.load_agent(agent_name)
        return cls._load_status.copy()

    @classmethod
    def is_loaded(cls, agent_name: str) -> bool:
        """Agent yÃ¼klÃ¼ mÃ¼ kontrol et"""
        return cls._load_status.get(agent_name, False)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AGENT DEFINITIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from agents.definitions import AGENTS_CONFIG
except ImportError:
    AGENTS_CONFIG = {}
    logger.warning("âš ï¸ agents/definitions.py bulunamadÄ±, varsayÄ±lan config kullanÄ±lÄ±yor")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NLP MANAGER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from managers.nlp import NLPManager
    NLP_AVAILABLE = True
except ImportError:
    NLPManager = None
    NLP_AVAILABLE = False
    logger.warning("âš ï¸ NLPManager bulunamadÄ±")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANA ENGINE SINIFI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class AgentEngine:
    """
    LotusAI Multi-Agent Koordinasyon Motoru

    Sorumluluklar:
    - Agent seÃ§imi ve yÃ¶nlendirme
    - LLM iletiÅŸimi (Gemini/Ollama)
    - GÃ¶rsel analiz ve dosya iÅŸleme
    - Dinamik prompt oluÅŸturma
    - Memory management
    - Context oluÅŸturma
    - Ajan bazlÄ± Ollama model seÃ§imi (SIDAR â†’ CODING_MODEL)
    """

    def __init__(self, memory_manager: Any, tools_dict: Dict[str, Any]):
        """
        Engine baÅŸlatÄ±cÄ±

        Args:
            memory_manager: HafÄ±za yÃ¶neticisi
            tools_dict: Manager ve araÃ§ dictionary'si
        """
        self.memory = memory_manager
        self.tools = tools_dict
        self.app_id = Config.PROJECT_NAME.lower().replace(" ", "-")

        # GPU durumu
        self.device = "cuda" if (Config.USE_GPU and TORCH_AVAILABLE) else "cpu"
        if self.device == "cuda":
            try:
                torch.cuda.empty_cache()
                logger.info(f"ğŸš€ Engine GPU aktif: {Config.GPU_INFO}")
            except Exception as e:
                logger.warning(f"GPU temizleme hatasÄ±: {e}")
                self.device = "cpu"

        # NLP Manager
        self.nlp: Optional[Any] = None
        if NLP_AVAILABLE:
            self.nlp = tools_dict.get('nlp') or NLPManager()

        # Agent'larÄ± yÃ¼kle
        self._initialize_agents()

        # Ollama model haritasÄ±nÄ± logla
        if Config.AI_PROVIDER == "ollama":
            logger.info(
                f"ğŸ¤– Ollama Model HaritasÄ± | "
                f"TEXT: {Config.TEXT_MODEL} | "
                f"VISION: {Config.VISION_MODEL} | "
                f"CODING (Sidar): {Config.CODING_MODEL}"
            )

        logger.info(f"âœ… AgentEngine hazÄ±r (Device: {self.device.upper()})")

    def _initialize_agents(self) -> None:
        """TÃ¼m agent'larÄ± baÅŸlat"""
        AgentLoader.load_all()

        self.agents: Dict[str, Any] = {}

        # ATLAS
        if AgentLoader.is_loaded("ATLAS"):
            AtlasAgent = AgentLoader.load_agent("ATLAS")
            self.agents["ATLAS"] = AtlasAgent(self.memory, self.tools)

        # GAYA
        if AgentLoader.is_loaded("GAYA"):
            GayaAgent = AgentLoader.load_agent("GAYA")
            self.agents["GAYA"] = GayaAgent(self.tools, self.nlp)

        # POYRAZ (Ã¶zel durum - tools'dan gelebilir)
        if "poyraz_special" in self.tools:
            self.agents["POYRAZ"] = self.tools["poyraz_special"]
        elif AgentLoader.is_loaded("POYRAZ"):
            PoyrazAgent = AgentLoader.load_agent("POYRAZ")
            self.agents["POYRAZ"] = PoyrazAgent(self.nlp, self.tools)

        # KURT
        if AgentLoader.is_loaded("KURT"):
            KurtAgent = AgentLoader.load_agent("KURT")
            self.agents["KURT"] = KurtAgent(self.tools)

        # SIDAR (Ã¶zel durum - tools'dan gelebilir)
        if "sidar_special" in self.tools:
            self.agents["SIDAR"] = self.tools["sidar_special"]
        elif AgentLoader.is_loaded("SIDAR"):
            SidarAgent = AgentLoader.load_agent("SIDAR")
            sidar_tools = {
                k: self.tools.get(k)
                for k in ['code', 'system', 'security', 'memory']
            }
            self.agents["SIDAR"] = SidarAgent(sidar_tools)

        # KERBEROS
        if AgentLoader.is_loaded("KERBEROS"):
            KerberosAgent = AgentLoader.load_agent("KERBEROS")
            self.agents["KERBEROS"] = KerberosAgent(self.tools)

        logger.info(f"Aktif agent'lar: {', '.join(self.agents.keys())}")

    def _resolve_ollama_model(self, agent: str, user_text: str = "") -> str:
        """
        Ollama iÃ§in ajan ve iÃ§eriÄŸe gÃ¶re kullanÄ±lacak modeli belirle.

        Kural:
        - SIDAR â†’ her zaman CODING_MODEL (qwen2.5-coder:7b)
        - GÃ¶rsel istek varsa â†’ VISION_MODEL (llama3.2-vision)
        - DiÄŸer tÃ¼m ajanlar â†’ TEXT_MODEL (gemma2:9b)

        Args:
            agent: Agent adÄ±
            user_text: KullanÄ±cÄ± metni (gÃ¶rsel/kod tetikleyici kontrolÃ¼ iÃ§in)

        Returns:
            Model adÄ± string
        """
        agent_upper = agent.upper()

        # SIDAR her zaman coding modeli kullanÄ±r
        if agent_upper == "SIDAR":
            logger.debug(f"SIDAR â†’ CODING_MODEL: {Config.CODING_MODEL}")
            return Config.CODING_MODEL

        # GÃ¶rsel tetikleyici varsa vision modeli
        clean = user_text.lower()
        if any(t in clean for t in EngineConfig.VISUAL_TRIGGERS):
            logger.debug(f"{agent} â†’ VISION_MODEL: {Config.VISION_MODEL}")
            return Config.VISION_MODEL

        # VarsayÄ±lan: metin modeli
        return Config.TEXT_MODEL

    def determine_agent(self, text: str) -> Optional[str]:
        """
        KullanÄ±cÄ± girdisine gÃ¶re en uygun agent'Ä± seÃ§

        Args:
            text: KullanÄ±cÄ± metni

        Returns:
            Agent adÄ± veya None
        """
        if not text:
            return "ATLAS"

        clean_text = self.nlp.clean_text(text.lower()) if self.nlp else text.lower()

        # Ã–ncelikli kontroller
        priority_checks = {
            "SIDAR": EngineConfig.SIDAR_CODE_TRIGGERS,
            "KERBEROS": ["kimsin", "yetki", "gÃ¼venlik", "kilit", "doÄŸrula", "tanÄ±"]
        }

        for agent, keywords in priority_checks.items():
            if any(k in clean_text for k in keywords):
                if agent in self.agents:
                    return agent

        # AGENTS_CONFIG'den kontrol
        for agent_name, agent_data in AGENTS_CONFIG.items():
            if agent_name not in self.agents:
                continue

            triggers = agent_data.get("wake_words", []) + agent_data.get("keys", [])
            if any(k.lower() in clean_text for k in triggers):
                return agent_name

        return "ATLAS"

    def _read_user_bio(self, user_obj: Optional[Dict] = None) -> str:
        """
        KullanÄ±cÄ± biyografisini oku

        Args:
            user_obj: KullanÄ±cÄ± bilgileri

        Returns:
            Bio metni veya boÅŸ string
        """
        bio_file = user_obj.get("bio_file", "halil_bio.txt") if user_obj else "halil_bio.txt"
        bio_path = Config.WORK_DIR / bio_file

        if not bio_path.exists():
            bio_path = Config.WORK_DIR / "halil_bio.txt"

        if bio_path.exists():
            try:
                content = bio_path.read_text(encoding="utf-8")
                return content[:EngineConfig.BIO_MAX_CHARS]
            except Exception as e:
                logger.error(f"Bio okuma hatasÄ±: {e}")

        return ""

    def _load_file_for_gemini(
        self,
        file_path: Union[str, Path]
    ) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
        """
        DosyayÄ± Gemini multimodal formatÄ±na hazÄ±rla

        Args:
            file_path: Dosya yolu

        Returns:
            Tuple[file data dict, error message]
        """
        path = Path(file_path)

        if not path.exists():
            return None, "Dosya bulunamadÄ±"

        ext = path.suffix.lower()
        mime_map = {
            ".png": "image/png",
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".webp": "image/webp",
            ".pdf": "application/pdf",
            ".txt": "text/plain"
        }

        mime_type = mime_map.get(ext, "application/octet-stream")

        try:
            data = path.read_bytes()
            return {"mime_type": mime_type, "data": data}, None

        except Exception as e:
            return None, f"Dosya okuma hatasÄ±: {str(e)}"

    def _extract_json_from_text(self, text: str) -> Optional[Dict]:
        """
        LLM Ã§Ä±ktÄ±sÄ±ndan JSON Ã§Ä±kar

        Args:
            text: LLM yanÄ±tÄ±

        Returns:
            JSON dict veya None
        """
        if not text:
            return None

        try:
            json_block = re.search(
                r'```(?:json)?\s*(\{.*?\})\s*```',
                text,
                re.DOTALL | re.IGNORECASE
            )

            if json_block:
                return json.loads(json_block.group(1))

            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())

            return None

        except json.JSONDecodeError as e:
            logger.debug(f"JSON parse hatasÄ±: {e}")
            return None

        except Exception as e:
            logger.error(f"JSON extraction hatasÄ±: {e}")
            return None

    def _build_time_date_response(self, clean_input: str) -> Optional[str]:
        """Saat/tarih/gÃ¼n sorularÄ± iÃ§in LLM'siz deterministik yanÄ±t Ã¼ret."""
        normalized = clean_input.strip().lower()
        if not normalized:
            return None

        # False positive azaltmak iÃ§in pattern tabanlÄ± intent tespiti
        is_time = any(re.match(p, normalized) for p in EngineConfig.TIME_QUERY_PATTERNS)
        is_date = any(re.match(p, normalized) for p in EngineConfig.DATE_QUERY_PATTERNS)
        is_day = any(re.match(p, normalized) for p in EngineConfig.DAY_QUERY_PATTERNS)

        # Kombin yanÄ±t: "tarih ve gÃ¼n" / "tarih gÃ¼n"
        is_date_day_combo = bool(
            re.match(r"^(tarih( ve)? gÃ¼n|tarih ve gÃ¼n)\??$", normalized)
            or re.match(r"^bugÃ¼n tarih ve gÃ¼n (ne|nedir)\??$", normalized)
        )

        if is_date_day_combo:
            is_date = True
            is_day = True

        if not any([is_time, is_date, is_day]):
            return None

        now = datetime.now()
        day_map = {
            "Monday": "Pazartesi",
            "Tuesday": "SalÄ±",
            "Wednesday": "Ã‡arÅŸamba",
            "Thursday": "PerÅŸembe",
            "Friday": "Cuma",
            "Saturday": "Cumartesi",
            "Sunday": "Pazar",
        }
        day_name = day_map.get(now.strftime("%A"), now.strftime("%A"))

        if is_time and not (is_date or is_day):
            return f"Sistem saati ÅŸu anda {now.strftime('%H:%M')}."

        if is_date and is_day:
            return f"BugÃ¼n {now.strftime('%d.%m.%Y')}, {day_name}."

        if is_date:
            return f"BugÃ¼nÃ¼n tarihi {now.strftime('%d.%m.%Y')}."

        if is_day:
            return f"BugÃ¼n gÃ¼nlerden {day_name}."

        return None

    def _build_core_prompt(
        self,
        agent_name: str,
        user_text: str,
        sec_result: Tuple[str, Optional[Dict], str],
        op_result: Optional[str] = None
    ) -> str:
        """
        Agent iÃ§in sistem prompt'u oluÅŸtur

        Args:
            agent_name: Agent adÄ±
            user_text: KullanÄ±cÄ± mesajÄ±
            sec_result: GÃ¼venlik sonucu (status, user_obj, sub_status)
            op_result: Operasyonel sonuÃ§ (opsiyonel)

        Returns:
            Sistem prompt'u
        """
        status_code, user_obj, sub_status = sec_result
        user_name = user_obj.get("name", "Misafir") if user_obj else "Misafir"

        agent_def = AGENTS_CONFIG.get(agent_name, {})
        base_sys = agent_def.get('sys', "YardÄ±mcÄ± bir yapay zeka sistemsin.")

        bio_content = ""
        if status_code in ["ONAYLI", "SES_ONAYLI"]:
            bio_content = self._read_user_bio(user_obj)

        time_str = datetime.now().strftime("%d.%m.%Y %H:%M")

        team_list = [name for name in self.agents.keys() if name != agent_name]
        team_str = ", ".join(team_list) if team_list else "YalnÄ±z"

        # Aktif model bilgisi (Ollama modunda)
        active_model_info = ""
        if Config.AI_PROVIDER == "ollama":
            active_model = self._resolve_ollama_model(agent_name, user_text)
            active_model_info = f"\nAktif Model: {active_model}"

        sections = [
            "### KÄ°MLÄ°K VE ROL ###",
            f"Sen LotusAI iÅŸletim sisteminin **{agent_name}** isimli uzman ajanÄ±sÄ±n.",
            f"GÃ¶rev TanÄ±mÄ±n: {base_sys}",
            "",
            "### ORTAM BÄ°LGÄ°LERÄ° ###",
            f"Tarih/Saat: {time_str}",
            f"KullanÄ±cÄ±: {user_name}",
            f"GÃ¼venlik Durumu: {status_code}",
            f"DiÄŸer Aktif Ajanlar: {team_str}",
            f"DonanÄ±m: {self.device.upper()}{active_model_info}"
        ]

        if sub_status == "TANIÅMA_MODU":
            sections.extend([
                "",
                "âš ï¸ GÃœVENLÄ°K PROTOKOLÃœ:",
                "KullanÄ±cÄ± henÃ¼z tam doÄŸrulanmadÄ±. Sadece tanÄ±ÅŸma ve temel bilgilendirme yap.",
                "Sistem yetkilerini kullandÄ±rma."
            ])

        agent_instance = self.agents.get(agent_name)
        if agent_instance and hasattr(agent_instance, "get_context_data"):
            try:
                if agent_name == "GAYA":
                    context = agent_instance.get_context_data(user_text)
                else:
                    context = agent_instance.get_context_data()

                if context:
                    sections.extend([
                        "",
                        "### CANLI VERÄ° BAÄLAMI ###",
                        context
                    ])

            except Exception as e:
                logger.error(f"Context alma hatasÄ± ({agent_name}): {e}")

        if op_result:
            sections.extend([
                "",
                "### OPERASYONEL ANALÄ°Z SONUCU ###",
                "Sistem bu gÃ¶revi Ã¶nceden iÅŸledi, sonucu yanÄ±tÄ±na dahil et:",
                op_result
            ])

        if bio_content:
            sections.extend([
                "",
                "### KULLANICI HAKKINDA Ã–ZEL BÄ°LGÄ°LER ###",
                bio_content
            ])

        sections.extend([
            "",
            "### YANIT STÄ°LÄ° ###",
            "Profesyonel, net ve LotusAI kimliÄŸine uygun konuÅŸ.",
            "Gereksiz giriÅŸ cÃ¼mlelerinden kaÃ§Ä±n."
        ])

        return "\n".join(sections)

    async def _handle_visual_tasks(
        self,
        clean_input: str,
        file_path: Optional[str],
        agent_name: str
    ) -> Tuple[Optional[Dict], Optional[str]]:
        """
        GÃ¶rsel analiz ve belge iÅŸleme

        Args:
            clean_input: TemizlenmiÅŸ kullanÄ±cÄ± metni
            file_path: Dosya yolu (opsiyonel)
            agent_name: Mevcut agent

        Returns:
            Tuple[gemini file part, operation result]
        """
        gemini_file_part = None
        op_result = None

        if file_path:
            gemini_file_part, error = self._load_file_for_gemini(file_path)
            if error:
                logger.warning(f"Dosya yÃ¼kleme hatasÄ±: {error}")

        is_visual_request = (
            any(trigger in clean_input for trigger in EngineConfig.VISUAL_TRIGGERS) or
            file_path is not None
        )

        if not is_visual_request or Config.AI_PROVIDER != "gemini":
            return gemini_file_part, op_result

        target_agent = "KERBEROS" if agent_name in ["KERBEROS", "ATLAS"] else "GAYA"

        if not gemini_file_part and 'camera' in self.tools and CV2_AVAILABLE:
            frame = self.tools['camera'].get_frame()
            if frame is not None:
                _, buffer = cv2.imencode('.jpg', frame)
                gemini_file_part = {
                    "mime_type": "image/jpeg",
                    "data": buffer.tobytes()
                }

        if gemini_file_part:
            analysis_prompt = (
                "Bu gÃ¶rseli detaylÄ±ca analiz et. "
                "EÄŸer fatura/finansal belge ise ÅŸu JSON formatÄ±nda Ã§Ä±kar: "
                "{ 'firma': '', 'toplam_tutar': '', 'tarih': '', 'urunler': [], 'is_invoice': true }. "
                "DeÄŸilse 'description' anahtarÄ±yla gÃ¶rseli aÃ§Ä±kla."
            )

            response = await self._query_gemini(
                target_agent,
                "GÃ¶rsel analiz uzmanÄ±sÄ±n.",
                [],
                analysis_prompt,
                gemini_file_part
            )

            analysis_data = self._extract_json_from_text(response["content"])

            if analysis_data:
                agent_instance = self.agents.get(target_agent)

                if analysis_data.get('is_invoice'):
                    if target_agent == "KERBEROS" and hasattr(agent_instance, "audit_invoice"):
                        op_result = agent_instance.audit_invoice(analysis_data)
                    elif target_agent == "GAYA" and hasattr(agent_instance, "process_invoice_result"):
                        op_result = agent_instance.process_invoice_result(analysis_data)
                else:
                    description = analysis_data.get('description', 'Analiz yapÄ±lamadÄ±')
                    op_result = f"GÃ¶rsel Analizi: {description}"

        return gemini_file_part, op_result

    async def get_response(
        self,
        agent_name: str,
        user_text: str,
        sec_result: Tuple[str, Optional[Dict], str],
        file_path: Optional[str] = None
    ) -> Dict[str, str]:
        """
        KullanÄ±cÄ± mesajÄ±na yanÄ±t Ã¼ret (Ana giriÅŸ noktasÄ±)

        Args:
            agent_name: SeÃ§ilen agent
            user_text: KullanÄ±cÄ± mesajÄ±
            sec_result: GÃ¼venlik sonucu
            file_path: Dosya yolu (opsiyonel)

        Returns:
            Agent yanÄ±tÄ± dict
        """
        clean_input = self.nlp.clean_text(user_text) if self.nlp else user_text.lower()

        status, user_obj, sub_status = sec_result

        # 1. GÃœVENLÄ°K KONTROLÃœ
        if status not in ["ONAYLI", "SES_ONAYLI"]:
            agent_name = "KERBEROS"

            if sub_status == "KAMERA_YOK":
                return {
                    "agent": "KERBEROS",
                    "content": (
                        "GÃ¼venlik protokolÃ¼ gereÄŸi sizi tanÄ±mam gerekiyor. "
                        "LÃ¼tfen kameranÄ±zÄ± aktive edin veya sesli doÄŸrulama yapÄ±n."
                    )
                }

        # 2. SELAMLAÅMA KONTROLÃœ
        if status in ["ONAYLI", "SES_ONAYLI"] and len(clean_input.split()) <= 3:
            if any(word in clean_input for word in EngineConfig.WELCOME_KEYWORDS):
                name = user_obj.get("name", "Halil Bey") if user_obj else "Halil Bey"
                return {
                    "agent": agent_name,
                    "content": (
                        f"HoÅŸ geldiniz {name}. LotusAI {self.device.upper()} "
                        f"destekli sistemleriyle aktif. Size nasÄ±l yardÄ±mcÄ± olabilirim?"
                    )
                }

        # 2.5 SAAT/TARÄ°H SORGULARI (hafÄ±za + LLM bypass)
        time_date_response = self._build_time_date_response(clean_input)
        if time_date_response:
            return {
                "agent": agent_name,
                "content": time_date_response
            }

        # 3. GÃ–RSEL/DOSYA Ä°ÅLEME
        gemini_file_part, op_result = await self._handle_visual_tasks(
            clean_input,
            file_path,
            agent_name
        )

        # 4. AGENT Ã–ZEL FONKSÄ°YON
        if not op_result:
            agent_instance = self.agents.get(agent_name)
            if agent_instance and hasattr(agent_instance, "auto_handle"):
                try:
                    op_result = await agent_instance.auto_handle(clean_input)
                except Exception as e:
                    logger.error(f"Agent auto_handle hatasÄ± ({agent_name}): {e}")

        # 5. LLM YANIT ÃœRETÄ°MÄ°
        sys_prompt = self._build_core_prompt(agent_name, clean_input, sec_result, op_result)

        try:
            history, _, _ = self.memory.load_context(
                agent_name,
                clean_input,
                max_items=EngineConfig.CONTEXT_MAX_ITEMS
            )
        except Exception as e:
            logger.warning(f"Memory yÃ¼kleme hatasÄ±: {e}")
            history = []

        if Config.AI_PROVIDER == "gemini" and GENAI_AVAILABLE:
            return await self._query_gemini(
                agent_name,
                sys_prompt,
                history,
                user_text,
                gemini_file_part
            )
        else:
            return await self._query_ollama(
                agent_name,
                sys_prompt,
                history,
                user_text
            )

    async def get_team_response(
        self,
        user_text: str,
        sec_result: Tuple[str, Optional[Dict], str]
    ) -> List[Dict[str, str]]:
        """
        TÃ¼m ekipten brifing al

        Args:
            user_text: KullanÄ±cÄ± sorusu
            sec_result: GÃ¼venlik sonucu

        Returns:
            Agent yanÄ±tlarÄ± listesi
        """
        status, _, _ = sec_result

        if status not in ["ONAYLI", "SES_ONAYLI"]:
            return [{
                "agent": "KERBEROS",
                "content": "GÃ¼venlik onayÄ± yetersiz, ekip brifingi baÅŸlatÄ±lamaz."
            }]

        tasks = []

        for agent_name in self.agents.keys():
            sys_prompt = self._build_core_prompt(
                agent_name,
                user_text,
                sec_result
            ) + "\n\n[GÃ–REV]: Konu hakkÄ±nda kendi uzmanlÄ±k alanÄ±ndan tek cÃ¼mlelik kÄ±sa brifing ver."

            if Config.AI_PROVIDER == "gemini" and GENAI_AVAILABLE:
                task = self._query_gemini(agent_name, sys_prompt, [], user_text)
            else:
                task = self._query_ollama(agent_name, sys_prompt, [], user_text)

            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        return [r for r in results if isinstance(r, dict)]

    async def _query_gemini(
        self,
        agent: str,
        sys_prompt: str,
        history: List[Dict],
        user_text: str,
        image_data: Optional[Dict] = None
    ) -> Dict[str, str]:
        """
        Gemini API'ye istek gÃ¶nder (Exponential backoff)

        Args:
            agent: Agent adÄ±
            sys_prompt: Sistem prompt'u
            history: Sohbet geÃ§miÅŸi
            user_text: KullanÄ±cÄ± mesajÄ±
            image_data: GÃ¶rsel data (opsiyonel)

        Returns:
            Agent yanÄ±tÄ±
        """
        if not GENAI_AVAILABLE:
            return {"agent": agent, "content": "âš ï¸ Gemini kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil"}

        agent_settings = Config.get_agent_settings(agent)
        api_key = agent_settings.get("key")
        model_name = agent_settings.get("model", Config.GEMINI_MODEL_DEFAULT)

        if not api_key:
            return {"agent": agent, "content": "âš ï¸ API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ"}

        genai.configure(api_key=api_key)

        gemini_history = []
        for msg in history:
            role = "user" if msg["role"] == "user" else "model"
            gemini_history.append({
                "role": role,
                "parts": [msg["content"]]
            })

        for attempt in range(EngineConfig.MAX_RETRIES):
            try:
                model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=sys_prompt
                )

                contents = [user_text]
                if image_data:
                    contents.append(image_data)

                chat = model.start_chat(history=gemini_history)

                response = await asyncio.to_thread(
                    chat.send_message,
                    contents
                )

                reply = response.text.strip()

                if self.memory:
                    self.memory.save(agent, "user", user_text)
                    self.memory.save(agent, "model", reply)

                return {"agent": agent, "content": reply}

            except Exception as e:
                wait_time = min(
                    EngineConfig.INITIAL_BACKOFF * (2 ** attempt),
                    EngineConfig.MAX_BACKOFF
                )

                logger.warning(
                    f"Gemini deneme {attempt + 1}/{EngineConfig.MAX_RETRIES} "
                    f"baÅŸarÄ±sÄ±z: {e}"
                )

                if attempt == EngineConfig.MAX_RETRIES - 1:
                    logger.error(f"Gemini kritik hatasÄ± ({agent}): {e}")
                    return {
                        "agent": agent,
                        "content": (
                            "Åu an merkezi sinir sistemime (Gemini) ulaÅŸamÄ±yorum. "
                            "LÃ¼tfen kÄ±sa sÃ¼re sonra tekrar deneyin."
                        )
                    }

                await asyncio.sleep(wait_time)

        return {"agent": agent, "content": "Beklenmeyen hata"}

    async def _query_ollama(
        self,
        agent: str,
        sys_prompt: str,
        history: List[Dict],
        user_text: str
    ) -> Dict[str, str]:
        """
        Ollama API'ye istek gÃ¶nder.
        Ajan bazlÄ± model seÃ§imi:
          - SIDAR  â†’ CODING_MODEL  (qwen2.5-coder:7b)
          - GÃ¶rsel â†’ VISION_MODEL  (llama3.2-vision)
          - DiÄŸer  â†’ TEXT_MODEL    (gemma2:9b)

        Args:
            agent: Agent adÄ±
            sys_prompt: Sistem prompt'u
            history: Sohbet geÃ§miÅŸi
            user_text: KullanÄ±cÄ± mesajÄ±

        Returns:
            Agent yanÄ±tÄ±
        """
        # Ajan ve iÃ§eriÄŸe gÃ¶re model seÃ§
        selected_model = self._resolve_ollama_model(agent, user_text)

        messages = [
            {"role": "system", "content": sys_prompt}
        ] + history + [
            {"role": "user", "content": user_text}
        ]

        # URL dÃ¼zeltmesi
        ollama_url = Config.OLLAMA_URL
        if not ollama_url.endswith("/chat"):
            base = ollama_url.rstrip("/")
            if "/api" not in base:
                ollama_url = f"{base}/api/chat"
            else:
                ollama_url = f"{base}/chat"

        logger.debug(f"Ollama isteÄŸi â†’ Agent: {agent} | Model: {selected_model} | URL: {ollama_url}")

        for attempt in range(2):
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.post(
                        ollama_url,
                        json={
                            "model": selected_model,
                            "messages": messages,
                            "stream": False
                        },
                        timeout=aiohttp.ClientTimeout(total=EngineConfig.OLLAMA_TIMEOUT)
                    ) as response:

                        if response.status == 200:
                            data = await response.json()
                            reply = data.get("message", {}).get("content", "").strip()

                            if self.memory:
                                self.memory.save(agent, "user", user_text)
                                self.memory.save(agent, "assistant", reply)

                            return {"agent": agent, "content": reply}

                        elif response.status == 404:
                            try:
                                err_json = await response.json()
                                err_msg = err_json.get("error", str(response.status))
                            except Exception:
                                err_msg = await response.text()

                            logger.error(f"Ollama Model/URL HatasÄ± (404): {err_msg}")

                            return {
                                "agent": agent,
                                "content": (
                                    f"âš ï¸ **Ollama HatasÄ± (404):** Ä°stenen model "
                                    f"`{selected_model}` bulunamadÄ±.\n"
                                    f"LÃ¼tfen terminalde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:\n"
                                    f"`ollama pull {selected_model}`"
                                )
                            }

                        else:
                            body = await response.text()
                            logger.error(
                                f"Ollama HTTP hatasÄ±: {response.status} | {body[:200]}"
                            )

            except asyncio.TimeoutError:
                logger.error(
                    f"Ollama timeout (Agent: {agent}, Model: {selected_model}, "
                    f"Deneme: {attempt + 1}/2)"
                )

            except aiohttp.ClientConnectorError as e:
                logger.error(f"Ollama baÄŸlantÄ± hatasÄ±: {e}")
                # BaÄŸlantÄ± hatasÄ± retry'dan fayda gÃ¶rmez, direkt Ã§Ä±k
                break

            except Exception as e:
                logger.error(f"Ollama beklenmeyen hata: {e}")

            if attempt == 0:
                await asyncio.sleep(2)

        return {
            "agent": agent,
            "content": (
                f"LotusAI yerel sunucusu (Ollama/{selected_model}) ÅŸu an yanÄ±t vermiyor. "
                "Terminal'de 'ollama serve' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n veya "
                f"'ollama pull {selected_model}' ile modeli indirin."
            )
        }

# """
# LotusAI Agent Engine - Multi-Agent Koordinasyon Motoru
# SÃ¼rÃ¼m: 2.6.0 (Multi-Model & Vision Support)
# AÃ§Ä±klama: Agent seÃ§imi, LLM iletiÅŸimi, gÃ¶rsel analiz ve dinamik yanÄ±t Ã¼retimi
# GÃ¼ncelleme: Model seÃ§imi akÄ±llandÄ±rÄ±ldÄ± (Sidar->Coder, Resim->Vision, DiÄŸerleri->Gemma)
# """

# import aiohttp
# import asyncio
# import json
# import logging
# import re
# import base64
# from datetime import datetime
# from pathlib import Path
# from typing import Optional, Dict, List, Any, Union, Tuple
# from dataclasses import dataclass
# from enum import Enum

# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # GOOGLE AI SDK
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# try:
#     import google.generativeai as genai
#     GENAI_AVAILABLE = True
# except ImportError:
#     GENAI_AVAILABLE = False
#     logging.warning("âš ï¸ google-generativeai yÃ¼klÃ¼ deÄŸil, Gemini devre dÄ±ÅŸÄ±")

# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # GÃ–RÃœNTÃœ Ä°ÅLEME
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# try:
#     from PIL import Image
#     PIL_AVAILABLE = True
# except ImportError:
#     PIL_AVAILABLE = False
#     logging.warning("âš ï¸ Pillow yÃ¼klÃ¼ deÄŸil, gÃ¶rÃ¼ntÃ¼ iÅŸleme kÄ±sÄ±tlÄ±")

# try:
#     import cv2
#     CV2_AVAILABLE = True
# except ImportError:
#     CV2_AVAILABLE = False
#     logging.warning("âš ï¸ opencv-python yÃ¼klÃ¼ deÄŸil, kamera desteÄŸi yok")

# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # GPU DESTEÄI
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# try:
#     import torch
#     TORCH_AVAILABLE = True
# except ImportError:
#     TORCH_AVAILABLE = False

# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # CORE MODÃœLLER
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# from config import Config

# logger = logging.getLogger("LotusAI.Engine")


# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # SABITLER
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# class EngineConfig:
#     """Engine Ã§alÄ±ÅŸma parametreleri"""
#     # Retry ayarlarÄ±
#     MAX_RETRIES: int = 5
#     INITIAL_BACKOFF: float = 2.0
#     MAX_BACKOFF: float = 32.0
    
#     # Timeout'lar
#     OLLAMA_TIMEOUT: int = 120
#     GEMINI_TIMEOUT: int = 60
    
#     # Metin limitleri
#     BIO_MAX_CHARS: int = 3000
#     CONTEXT_MAX_ITEMS: int = 10
    
#     # Dosya tipleri
#     SUPPORTED_IMAGE_TYPES = {'.png', '.jpg', '.jpeg', '.webp'}
#     SUPPORTED_DOC_TYPES = {'.pdf', '.txt'}
    
#     # Prompt temalarÄ±
#     WELCOME_KEYWORDS = ["selam", "merhaba", "geldim", "buradayÄ±m", "hey lotus"]
#     VISUAL_TRIGGERS = ["fatura", "fiÅŸ", "dekont", "hesap", "oku", "iÅŸle", 
#                       "ne yazÄ±yor", "analiz et", "gÃ¶ster"]


# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # YARDIMCI SINIFLAR
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# @dataclass
# class AgentResponse:
#     """Agent yanÄ±t yapÄ±sÄ±"""
#     agent: str
#     content: str
#     metadata: Optional[Dict[str, Any]] = None


# class SecurityStatus(Enum):
#     """GÃ¼venlik durumlarÄ±"""
#     APPROVED = "ONAYLI"
#     VOICE_APPROVED = "SES_ONAYLI"
#     PENDING = "BEKLEMEDE"
#     DENIED = "REDDEDÄ°LDÄ°"
#     NO_CAMERA = "KAMERA_YOK"
#     INTRO_MODE = "TANIÅMA_MODU"


# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # AGENT YÃ–NETÄ°CÄ°SÄ°
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# class AgentLoader:
#     """Agent modÃ¼llerini dinamik olarak yÃ¼kler"""
    
#     _loaded_agents: Dict[str, Any] = {}
#     _load_status: Dict[str, bool] = {}
    
#     AGENT_MAP = {
#         "ATLAS": ("atlas", "AtlasAgent"),
#         "GAYA": ("gaya", "GayaAgent"),
#         "POYRAZ": ("poyraz", "PoyrazAgent"),
#         "KURT": ("kurt", "KurtAgent"),
#         "SIDAR": ("sidar", "SidarAgent"),
#         "KERBEROS": ("kerberos", "KerberosAgent")
#     }
    
#     @classmethod
#     def load_agent(cls, agent_name: str) -> Optional[type]:
#         """
#         Agent class'Ä±nÄ± yÃ¼kle
        
#         Args:
#             agent_name: Agent adÄ± (ATLAS, GAYA, vb.)
        
#         Returns:
#             Agent class veya None
#         """
#         if agent_name in cls._loaded_agents:
#             return cls._loaded_agents[agent_name]
        
#         if agent_name not in cls.AGENT_MAP:
#             logger.warning(f"Bilinmeyen agent: {agent_name}")
#             return None
        
#         module_name, class_name = cls.AGENT_MAP[agent_name]
        
#         try:
#             module = __import__(f"agents.{module_name}", fromlist=[class_name])
#             agent_class = getattr(module, class_name)
            
#             cls._loaded_agents[agent_name] = agent_class
#             cls._load_status[agent_name] = True
#             logger.info(f"âœ… {agent_name} agent yÃ¼klendi")
            
#             return agent_class
        
#         except (ImportError, AttributeError) as e:
#             logger.debug(f"Agent yÃ¼klenemedi ({agent_name}): {e}")
#             cls._load_status[agent_name] = False
#             return None
    
#     @classmethod
#     def load_all(cls) -> Dict[str, bool]:
#         """TÃ¼m agent'larÄ± yÃ¼kle ve durum dÃ¶ndÃ¼r"""
#         for agent_name in cls.AGENT_MAP.keys():
#             cls.load_agent(agent_name)
#         return cls._load_status.copy()
    
#     @classmethod
#     def is_loaded(cls, agent_name: str) -> bool:
#         """Agent yÃ¼klÃ¼ mÃ¼ kontrol et"""
#         return cls._load_status.get(agent_name, False)


# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # AGENT DEFINITIONS
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# try:
#     from agents.definitions import AGENTS_CONFIG
# except ImportError:
#     AGENTS_CONFIG = {}
#     logger.warning("âš ï¸ agents/definitions.py bulunamadÄ±, varsayÄ±lan config kullanÄ±lÄ±yor")


# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # NLP MANAGER
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# try:
#     from managers.nlp import NLPManager
#     NLP_AVAILABLE = True
# except ImportError:
#     NLPManager = None
#     NLP_AVAILABLE = False
#     logger.warning("âš ï¸ NLPManager bulunamadÄ±")


# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# # ANA ENGINE SINIFI
# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# class AgentEngine:
#     """
#     LotusAI Multi-Agent Koordinasyon Motoru
#     """
    
#     def __init__(self, memory_manager: Any, tools_dict: Dict[str, Any]):
#         """
#         Engine baÅŸlatÄ±cÄ±
        
#         Args:
#             memory_manager: HafÄ±za yÃ¶neticisi
#             tools_dict: Manager ve araÃ§ dictionary'si
#         """
#         self.memory = memory_manager
#         self.tools = tools_dict
#         self.app_id = Config.PROJECT_NAME.lower().replace(" ", "-")
        
#         # GPU durumu
#         self.device = "cuda" if (Config.USE_GPU and TORCH_AVAILABLE) else "cpu"
#         if self.device == "cuda":
#             try:
#                 torch.cuda.empty_cache()
#                 logger.info(f"ğŸš€ Engine GPU aktif: {Config.GPU_INFO}")
#             except Exception as e:
#                 logger.warning(f"GPU temizleme hatasÄ±: {e}")
#                 self.device = "cpu"
        
#         # NLP Manager
#         self.nlp: Optional[Any] = None
#         if NLP_AVAILABLE:
#             self.nlp = tools_dict.get('nlp') or NLPManager()
        
#         # Agent'larÄ± yÃ¼kle
#         self._initialize_agents()
        
#         logger.info(f"âœ… AgentEngine hazÄ±r (Device: {self.device.upper()})")
    
#     def _initialize_agents(self) -> None:
#         """TÃ¼m agent'larÄ± baÅŸlat"""
#         # Agent loader'Ä± kullan
#         AgentLoader.load_all()
        
#         # Agent instance'larÄ±nÄ± oluÅŸtur
#         self.agents: Dict[str, Any] = {}
        
#         # ATLAS
#         if AgentLoader.is_loaded("ATLAS"):
#             AtlasAgent = AgentLoader.load_agent("ATLAS")
#             self.agents["ATLAS"] = AtlasAgent(self.memory, self.tools)
        
#         # GAYA
#         if AgentLoader.is_loaded("GAYA"):
#             GayaAgent = AgentLoader.load_agent("GAYA")
#             self.agents["GAYA"] = GayaAgent(self.tools, self.nlp)
        
#         # POYRAZ (Ã¶zel durum - tools'dan gelebilir)
#         if "poyraz_special" in self.tools:
#             self.agents["POYRAZ"] = self.tools["poyraz_special"]
#         elif AgentLoader.is_loaded("POYRAZ"):
#             PoyrazAgent = AgentLoader.load_agent("POYRAZ")
#             self.agents["POYRAZ"] = PoyrazAgent(self.nlp, self.tools)
        
#         # KURT
#         if AgentLoader.is_loaded("KURT"):
#             KurtAgent = AgentLoader.load_agent("KURT")
#             self.agents["KURT"] = KurtAgent(self.tools)
        
#         # SIDAR (Ã¶zel durum - tools'dan gelebilir)
#         if "sidar_special" in self.tools:
#             self.agents["SIDAR"] = self.tools["sidar_special"]
#         elif AgentLoader.is_loaded("SIDAR"):
#             SidarAgent = AgentLoader.load_agent("SIDAR")
#             sidar_tools = {
#                 k: self.tools.get(k) 
#                 for k in ['code', 'system', 'security', 'memory']
#             }
#             self.agents["SIDAR"] = SidarAgent(sidar_tools)
        
#         # KERBEROS
#         if AgentLoader.is_loaded("KERBEROS"):
#             KerberosAgent = AgentLoader.load_agent("KERBEROS")
#             self.agents["KERBEROS"] = KerberosAgent(self.tools)
        
#         logger.info(f"Aktif agent'lar: {', '.join(self.agents.keys())}")
    
#     def determine_agent(self, text: str) -> Optional[str]:
#         """
#         KullanÄ±cÄ± girdisine gÃ¶re en uygun agent'Ä± seÃ§
        
#         Args:
#             text: KullanÄ±cÄ± metni
        
#         Returns:
#             Agent adÄ± veya None
#         """
#         if not text:
#             return "ATLAS"
        
#         # Metni temizle
#         clean_text = self.nlp.clean_text(text.lower()) if self.nlp else text.lower()
        
#         # Ã–ncelikli kontroller
#         priority_checks = {
#             "SIDAR": ["sistem", "kod", "hata", "terminal", "log", "debug"],
#             "KERBEROS": ["kimsin", "yetki", "gÃ¼venlik", "kilit", "doÄŸrula", "tanÄ±"]
#         }
        
#         for agent, keywords in priority_checks.items():
#             if any(k in clean_text for k in keywords):
#                 if agent in self.agents:
#                     return agent
        
#         # AGENTS_CONFIG'den kontrol
#         for agent_name, agent_data in AGENTS_CONFIG.items():
#             if agent_name not in self.agents:
#                 continue
            
#             triggers = agent_data.get("wake_words", []) + agent_data.get("keys", [])
#             if any(k.lower() in clean_text for k in triggers):
#                 return agent_name
        
#         return "ATLAS"
    
#     def _read_user_bio(self, user_obj: Optional[Dict] = None) -> str:
#         """
#         KullanÄ±cÄ± biyografisini oku
        
#         Args:
#             user_obj: KullanÄ±cÄ± bilgileri
        
#         Returns:
#             Bio metni veya boÅŸ string
#         """
#         bio_file = user_obj.get("bio_file", "halil_bio.txt") if user_obj else "halil_bio.txt"
#         bio_path = Config.WORK_DIR / bio_file
        
#         # Fallback
#         if not bio_path.exists():
#             bio_path = Config.WORK_DIR / "halil_bio.txt"
        
#         if bio_path.exists():
#             try:
#                 content = bio_path.read_text(encoding="utf-8")
#                 return content[:EngineConfig.BIO_MAX_CHARS]
#             except Exception as e:
#                 logger.error(f"Bio okuma hatasÄ±: {e}")
        
#         return ""
    
#     def _load_file_for_gemini(
#         self, 
#         file_path: Union[str, Path]
#     ) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
#         """
#         DosyayÄ± Gemini multimodal formatÄ±na hazÄ±rla
        
#         Args:
#             file_path: Dosya yolu
        
#         Returns:
#             Tuple[file data dict, error message]
#         """
#         path = Path(file_path)
        
#         if not path.exists():
#             return None, "Dosya bulunamadÄ±"
        
#         # MIME type belirleme
#         ext = path.suffix.lower()
#         mime_map = {
#             ".png": "image/png",
#             ".jpg": "image/jpeg",
#             ".jpeg": "image/jpeg",
#             ".webp": "image/webp",
#             ".pdf": "application/pdf",
#             ".txt": "text/plain"
#         }
        
#         mime_type = mime_map.get(ext, "application/octet-stream")
        
#         try:
#             data = path.read_bytes()
#             return {"mime_type": mime_type, "data": data}, None
        
#         except Exception as e:
#             return None, f"Dosya okuma hatasÄ±: {str(e)}"
    
#     def _load_file_for_ollama(self, file_path: Union[str, Path]) -> Tuple[Optional[str], Optional[str]]:
#         """
#         DosyayÄ± Ollama iÃ§in Base64 string formatÄ±na hazÄ±rla
        
#         Returns:
#             Tuple[base64 string, error message]
#         """
#         path = Path(file_path)
#         if not path.exists():
#             return None, "Dosya bulunamadÄ±"
            
#         try:
#             ext = path.suffix.lower()
#             if ext in EngineConfig.SUPPORTED_IMAGE_TYPES:
#                 data = path.read_bytes()
#                 b64_str = base64.b64encode(data).decode('utf-8')
#                 return b64_str, None
#             elif ext == ".txt":
#                 # Text dosyalarÄ±nÄ± string olarak dÃ¶n
#                 return path.read_text(encoding="utf-8"), None
#             else:
#                 return None, f"Ollama bu dosya tÃ¼rÃ¼nÃ¼ desteklemiyor: {ext}"
#         except Exception as e:
#             return None, f"Dosya okuma hatasÄ±: {str(e)}"

#     def _extract_json_from_text(self, text: str) -> Optional[Dict]:
#         """
#         LLM Ã§Ä±ktÄ±sÄ±ndan JSON Ã§Ä±kar
        
#         Args:
#             text: LLM yanÄ±tÄ±
        
#         Returns:
#             JSON dict veya None
#         """
#         if not text:
#             return None
        
#         try:
#             # 1. Markdown kod bloÄŸu
#             json_block = re.search(
#                 r'```(?:json)?\s*(\{.*?\})\s*```',
#                 text,
#                 re.DOTALL | re.IGNORECASE
#             )
            
#             if json_block:
#                 return json.loads(json_block.group(1))
            
#             # 2. DÃ¼z JSON object
#             json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text, re.DOTALL)
#             if json_match:
#                 return json.loads(json_match.group())
            
#             return None
        
#         except json.JSONDecodeError as e:
#             logger.debug(f"JSON parse hatasÄ±: {e}")
#             return None
        
#         except Exception as e:
#             logger.error(f"JSON extraction hatasÄ±: {e}")
#             return None
    
#     def _build_core_prompt(
#         self,
#         agent_name: str,
#         user_text: str,
#         sec_result: Tuple[str, Optional[Dict], str],
#         op_result: Optional[str] = None
#     ) -> str:
#         """
#         Agent iÃ§in sistem prompt'u oluÅŸtur
        
#         Args:
#             agent_name: Agent adÄ±
#             user_text: KullanÄ±cÄ± mesajÄ±
#             sec_result: GÃ¼venlik sonucu (status, user_obj, sub_status)
#             op_result: Operasyonel sonuÃ§ (opsiyonel)
        
#         Returns:
#             Sistem prompt'u
#         """
#         status_code, user_obj, sub_status = sec_result
#         user_name = user_obj.get("name", "Misafir") if user_obj else "Misafir"
        
#         # Agent tanÄ±mÄ±
#         agent_def = AGENTS_CONFIG.get(agent_name, {})
#         base_sys = agent_def.get('sys', "YardÄ±mcÄ± bir yapay zeka sistemsin.")
        
#         # Bio iÃ§eriÄŸi
#         bio_content = ""
#         if status_code in ["ONAYLI", "SES_ONAYLI"]:
#             bio_content = self._read_user_bio(user_obj)
        
#         # Zaman bilgisi
#         time_str = datetime.now().strftime("%d.%m.%Y %H:%M")
        
#         # DiÄŸer agent'lar
#         team_list = [name for name in self.agents.keys() if name != agent_name]
#         team_str = ", ".join(team_list) if team_list else "YalnÄ±z"
        
#         # Prompt oluÅŸtur
#         sections = [
#             "### KÄ°MLÄ°K VE ROL ###",
#             f"Sen LotusAI iÅŸletim sisteminin **{agent_name}** isimli uzman ajanÄ±sÄ±n.",
#             f"GÃ¶rev TanÄ±mÄ±n: {base_sys}",
#             "",
#             "### ORTAM BÄ°LGÄ°LERÄ° ###",
#             f"Tarih/Saat: {time_str}",
#             f"KullanÄ±cÄ±: {user_name}",
#             f"GÃ¼venlik Durumu: {status_code}",
#             f"DiÄŸer Aktif Ajanlar: {team_str}",
#             f"DonanÄ±m: {self.device.upper()}"
#         ]
        
#         # GÃ¼venlik uyarÄ±sÄ±
#         if sub_status == "TANIÅMA_MODU":
#             sections.extend([
#                 "",
#                 "âš ï¸ GÃœVENLÄ°K PROTOKOLÃœ:",
#                 "KullanÄ±cÄ± henÃ¼z tam doÄŸrulanmadÄ±. Sadece tanÄ±ÅŸma ve temel bilgilendirme yap.",
#                 "Sistem yetkilerini kullandÄ±rma."
#             ])
        
#         # Agent context
#         agent_instance = self.agents.get(agent_name)
#         if agent_instance and hasattr(agent_instance, "get_context_data"):
#             try:
#                 if agent_name == "GAYA":
#                     context = agent_instance.get_context_data(user_text)
#                 else:
#                     context = agent_instance.get_context_data()
                
#                 if context:
#                     sections.extend([
#                         "",
#                         "### CANLI VERÄ° BAÄLAMI ###",
#                         context
#                     ])
            
#             except Exception as e:
#                 logger.error(f"Context alma hatasÄ± ({agent_name}): {e}")
        
#         # Operasyonel sonuÃ§
#         if op_result:
#             sections.extend([
#                 "",
#                 "### OPERASYONEL ANALÄ°Z SONUCU ###",
#                 "Sistem bu gÃ¶revi Ã¶nceden iÅŸledi, sonucu yanÄ±tÄ±na dahil et:",
#                 op_result
#             ])
        
#         # Bio
#         if bio_content:
#             sections.extend([
#                 "",
#                 "### KULLANICI HAKKINDA Ã–ZEL BÄ°LGÄ°LER ###",
#                 bio_content
#             ])
        
#         # Stil notu
#         sections.extend([
#             "",
#             "### YANIT STÄ°LÄ° ###",
#             "Profesyonel, net ve LotusAI kimliÄŸine uygun konuÅŸ.",
#             "Gereksiz giriÅŸ cÃ¼mlelerinden kaÃ§Ä±n."
#         ])
        
#         return "\n".join(sections)
    
#     async def _handle_visual_tasks(
#         self,
#         clean_input: str,
#         file_path: Optional[str],
#         agent_name: str
#     ) -> Tuple[Any, Optional[str]]:
#         """
#         GÃ¶rsel analiz ve belge iÅŸleme (Gemini & Ollama Vision)
#         """
#         ai_file_data = None
#         op_result = None
        
#         # Dosya yÃ¼kle
#         if file_path:
#             if Config.AI_PROVIDER == "gemini":
#                 ai_file_data, error = self._load_file_for_gemini(file_path)
#             else:
#                 ai_file_data, error = self._load_file_for_ollama(file_path)
                
#             if error:
#                 logger.warning(f"Dosya yÃ¼kleme hatasÄ±: {error}")
        
#         # GÃ¶rsel istek kontrolÃ¼
#         is_visual_request = (
#             any(trigger in clean_input for trigger in EngineConfig.VISUAL_TRIGGERS) or
#             file_path is not None
#         )
        
#         # Kameradan gÃ¶rÃ¼ntÃ¼ al (dosya yoksa ve trigger varsa)
#         if not ai_file_data and is_visual_request and 'camera' in self.tools and CV2_AVAILABLE:
#             frame = self.tools['camera'].get_frame()
#             if frame is not None:
#                 _, buffer = cv2.imencode('.jpg', frame)
                
#                 if Config.AI_PROVIDER == "gemini":
#                     ai_file_data = {"mime_type": "image/jpeg", "data": buffer.tobytes()}
#                 else:
#                     # Ollama iÃ§in Base64
#                     ai_file_data = base64.b64encode(buffer).decode('utf-8')
        
#         # GÃ¶rsel analiz
#         if ai_file_data:
#             target_agent = "KERBEROS" if agent_name in ["KERBEROS", "ATLAS"] else "GAYA"
#             analysis_prompt = (
#                 "Bu gÃ¶rseli detaylÄ±ca analiz et. "
#                 "EÄŸer fatura/finansal belge ise ÅŸu JSON formatÄ±nda Ã§Ä±kar: "
#                 "{ 'firma': '', 'toplam_tutar': '', 'tarih': '', 'urunler': [], 'is_invoice': true }. "
#                 "DeÄŸilse 'description' anahtarÄ±yla gÃ¶rseli aÃ§Ä±kla."
#             )
            
#             # Provider'a gÃ¶re sorgu
#             if Config.AI_PROVIDER == "gemini":
#                 response = await self._query_gemini(target_agent, "GÃ¶rsel analiz uzmanÄ±sÄ±n.", [], analysis_prompt, ai_file_data)
#             else:
#                 # Ollama Vision Sorgusu (Llama 3.2 Vision)
#                 response = await self._query_ollama(target_agent, "GÃ¶rsel analiz uzmanÄ±sÄ±n.", [], analysis_prompt, image_data=ai_file_data)
            
#             analysis_data = self._extract_json_from_text(response["content"])
            
#             if analysis_data:
#                 agent_instance = self.agents.get(target_agent)
                
#                 if analysis_data.get('is_invoice'):
#                     # Fatura iÅŸleme
#                     if target_agent == "KERBEROS" and hasattr(agent_instance, "audit_invoice"):
#                         op_result = agent_instance.audit_invoice(analysis_data)
#                     elif target_agent == "GAYA" and hasattr(agent_instance, "process_invoice_result"):
#                         op_result = agent_instance.process_invoice_result(analysis_data)
#                 else:
#                     # Genel gÃ¶rsel
#                     description = analysis_data.get('description', 'Analiz yapÄ±lamadÄ±')
#                     op_result = f"GÃ¶rsel Analizi: {description}"
#             else:
#                 # JSON dÃ¶nmezse ham metni kullan
#                 op_result = f"GÃ¶rsel Ä°Ã§eriÄŸi: {response['content']}"
        
#         return ai_file_data, op_result
    
#     async def get_response(
#         self,
#         agent_name: str,
#         user_text: str,
#         sec_result: Tuple[str, Optional[Dict], str],
#         file_path: Optional[str] = None
#     ) -> Dict[str, str]:
#         """
#         KullanÄ±cÄ± mesajÄ±na yanÄ±t Ã¼ret (Ana giriÅŸ noktasÄ±)
        
#         Args:
#             agent_name: SeÃ§ilen agent
#             user_text: KullanÄ±cÄ± mesajÄ±
#             sec_result: GÃ¼venlik sonucu
#             file_path: Dosya yolu (opsiyonel)
        
#         Returns:
#             Agent yanÄ±tÄ± dict
#         """
#         # Metni temizle
#         clean_input = self.nlp.clean_text(user_text) if self.nlp else user_text.lower()
        
#         status, user_obj, sub_status = sec_result
        
#         # 1. GÃœVENLÄ°K KONTROLÃœ
#         if status not in ["ONAYLI", "SES_ONAYLI"]:
#             agent_name = "KERBEROS"
            
#             if sub_status == "KAMERA_YOK":
#                 return {
#                     "agent": "KERBEROS",
#                     "content": (
#                         "GÃ¼venlik protokolÃ¼ gereÄŸi sizi tanÄ±mam gerekiyor. "
#                         "LÃ¼tfen kameranÄ±zÄ± aktive edin veya sesli doÄŸrulama yapÄ±n."
#                     )
#                 }
        
#         # 2. SELAMLAÅMA KONTROLÃœ
#         if status in ["ONAYLI", "SES_ONAYLI"] and len(clean_input.split()) <= 3:
#             if any(word in clean_input for word in EngineConfig.WELCOME_KEYWORDS):
#                 name = user_obj.get("name", "Halil Bey") if user_obj else "Halil Bey"
#                 return {
#                     "agent": agent_name,
#                     "content": (
#                         f"HoÅŸ geldiniz {name}. LotusAI {self.device.upper()} "
#                         f"destekli sistemleriyle aktif. Size nasÄ±l yardÄ±mcÄ± olabilirim?"
#                     )
#                 }
        
#         # 3. GÃ–RSEL/DOSYA Ä°ÅLEME
#         # ai_file_data provider'a gÃ¶re deÄŸiÅŸir (dict veya str)
#         ai_file_data, op_result = await self._handle_visual_tasks(
#             clean_input,
#             file_path,
#             agent_name
#         )
        
#         # 4. AGENT Ã–ZEL FONKSÄ°YON
#         if not op_result:
#             agent_instance = self.agents.get(agent_name)
#             if agent_instance and hasattr(agent_instance, "auto_handle"):
#                 try:
#                     op_result = await agent_instance.auto_handle(clean_input)
#                 except Exception as e:
#                     logger.error(f"Agent auto_handle hatasÄ± ({agent_name}): {e}")
        
#         # 5. LLM YANIT ÃœRETÄ°MÄ°
#         sys_prompt = self._build_core_prompt(agent_name, clean_input, sec_result, op_result)
        
#         # Memory'den geÃ§miÅŸ al
#         try:
#             history, _, _ = self.memory.load_context(
#                 agent_name,
#                 clean_input,
#                 max_items=EngineConfig.CONTEXT_MAX_ITEMS
#             )
#         except Exception as e:
#             logger.warning(f"Memory yÃ¼kleme hatasÄ±: {e}")
#             history = []
        
#         # Provider'a gÃ¶re query
#         if Config.AI_PROVIDER == "gemini" and GENAI_AVAILABLE:
#             return await self._query_gemini(
#                 agent_name,
#                 sys_prompt,
#                 history,
#                 user_text,
#                 ai_file_data
#             )
#         else:
#             # Ollama'ya gÃ¶nderirken gÃ¶rsel varsa image_payload olarak ayarla
#             # ai_file_data zaten base64 string veya None dÃ¶ner (_handle_visual_tasks iÃ§inde)
#             image_payload = ai_file_data if (isinstance(ai_file_data, str) and len(ai_file_data) > 100) else None
            
#             return await self._query_ollama(
#                 agent_name,
#                 sys_prompt,
#                 history,
#                 user_text,
#                 image_data=image_payload
#             )
    
#     async def get_team_response(
#         self,
#         user_text: str,
#         sec_result: Tuple[str, Optional[Dict], str]
#     ) -> List[Dict[str, str]]:
#         """
#         TÃ¼m ekipten brifing al
        
#         Args:
#             user_text: KullanÄ±cÄ± sorusu
#             sec_result: GÃ¼venlik sonucu
        
#         Returns:
#             Agent yanÄ±tlarÄ± listesi
#         """
#         status, _, _ = sec_result
        
#         if status not in ["ONAYLI", "SES_ONAYLI"]:
#             return [{
#                 "agent": "KERBEROS",
#                 "content": "GÃ¼venlik onayÄ± yetersiz, ekip brifingi baÅŸlatÄ±lamaz."
#             }]
        
#         # TÃ¼m agent'lar iÃ§in task oluÅŸtur
#         tasks = []
        
#         for agent_name in self.agents.keys():
#             sys_prompt = self._build_core_prompt(
#                 agent_name,
#                 user_text,
#                 sec_result
#             ) + "\n\n[GÃ–REV]: Konu hakkÄ±nda kendi uzmanlÄ±k alanÄ±ndan tek cÃ¼mlelik kÄ±sa brifing ver."
            
#             if Config.AI_PROVIDER == "gemini" and GENAI_AVAILABLE:
#                 task = self._query_gemini(agent_name, sys_prompt, [], user_text)
#             else:
#                 task = self._query_ollama(agent_name, sys_prompt, [], user_text)
            
#             tasks.append(task)
        
#         # Paralel Ã§alÄ±ÅŸtÄ±r
#         results = await asyncio.gather(*tasks, return_exceptions=True)
        
#         # HatalarÄ± filtrele
#         return [r for r in results if isinstance(r, dict)]
    
#     async def _query_gemini(
#         self,
#         agent: str,
#         sys_prompt: str,
#         history: List[Dict],
#         user_text: str,
#         image_data: Optional[Dict] = None
#     ) -> Dict[str, str]:
#         """
#         Gemini API'ye istek gÃ¶nder (Exponential backoff)
#         """
#         if not GENAI_AVAILABLE:
#             return {
#                 "agent": agent,
#                 "content": "âš ï¸ Gemini kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil"
#             }
        
#         # API Key al
#         agent_settings = Config.get_agent_settings(agent)
#         api_key = agent_settings.get("key")
#         model_name = agent_settings.get("model", Config.GEMINI_MODEL_DEFAULT)
        
#         if not api_key:
#             return {
#                 "agent": agent,
#                 "content": "âš ï¸ API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ"
#             }
        
#         # Gemini yapÄ±landÄ±r
#         genai.configure(api_key=api_key)
        
#         # History formatla
#         gemini_history = []
#         for msg in history:
#             role = "user" if msg["role"] == "user" else "model"
#             gemini_history.append({
#                 "role": role,
#                 "parts": [msg["content"]]
#             })
        
#         # Retry dÃ¶ngÃ¼sÃ¼
#         for attempt in range(EngineConfig.MAX_RETRIES):
#             try:
#                 # Model oluÅŸtur
#                 model = genai.GenerativeModel(
#                     model_name=model_name,
#                     system_instruction=sys_prompt
#                 )
                
#                 # Ä°Ã§erik hazÄ±rla
#                 contents = [user_text]
#                 if image_data:
#                     contents.append(image_data)
                
#                 # Chat baÅŸlat
#                 chat = model.start_chat(history=gemini_history)
                
#                 # YanÄ±t al (async thread)
#                 response = await asyncio.to_thread(
#                     chat.send_message,
#                     contents
#                 )
                
#                 reply = response.text.strip()
                
#                 # Memory'ye kaydet
#                 if self.memory:
#                     self.memory.save(agent, "user", user_text)
#                     self.memory.save(agent, "model", reply)
                
#                 return {"agent": agent, "content": reply}
            
#             except Exception as e:
#                 wait_time = min(
#                     EngineConfig.INITIAL_BACKOFF * (2 ** attempt),
#                     EngineConfig.MAX_BACKOFF
#                 )
                
#                 logger.warning(
#                     f"Gemini deneme {attempt + 1}/{EngineConfig.MAX_RETRIES} "
#                     f"baÅŸarÄ±sÄ±z: {e}"
#                 )
                
#                 if attempt == EngineConfig.MAX_RETRIES - 1:
#                     logger.error(f"Gemini kritik hatasÄ± ({agent}): {e}")
#                     return {
#                         "agent": agent,
#                         "content": (
#                             "Åu an merkezi sinir sistemime (Gemini) ulaÅŸamÄ±yorum. "
#                             "LÃ¼tfen kÄ±sa sÃ¼re sonra tekrar deneyin."
#                         )
#                     }
                
#                 await asyncio.sleep(wait_time)
        
#         # Buraya normalde gelmemeli
#         return {"agent": agent, "content": "Beklenmeyen hata"}
    
#     async def _query_ollama(
#         self,
#         agent: str,
#         sys_prompt: str,
#         history: List[Dict],
#         user_text: str,
#         image_data: Optional[str] = None
#     ) -> Dict[str, str]:
#         """
#         Ollama API'ye istek gÃ¶nder (Otomatik Model SeÃ§imi ve Vision DesteÄŸi)
#         """
        
#         # 1. AKILLI MODEL SEÃ‡Ä°MÄ°
#         # EÄŸer gÃ¶rsel varsa -> Vision Model (llama3.2-vision)
#         if image_data:
#             model = getattr(Config, 'VISION_MODEL', 'llama3.2-vision')
#             sys_prompt += "\n[GÃ–REV]: GÃ¶rseli detaylÄ±ca analiz et ve soruyu buna gÃ¶re yanÄ±tla."
            
#         # EÄŸer ajan SIDAR ise -> Coding Model (qwen2.5-coder)
#         elif agent == "SIDAR":
#             model = getattr(Config, 'CODING_MODEL', 'qwen2.5-coder:7b')
#             sys_prompt += "\n[MOD]: YazÄ±lÄ±m MimarÄ± ve Kodlama UzmanÄ±"
            
#         # DiÄŸerleri -> Standart Text Model (gemma2:9b)
#         else:
#             model = getattr(Config, 'TEXT_MODEL', 'gemma2:9b')
        
#         # 2. MESAJ YAPISI
#         user_msg = {"role": "user", "content": user_text}
        
#         # EÄŸer gÃ¶rsel varsa user mesajÄ±na ekle (Base64 string)
#         if image_data:
#             user_msg["images"] = [image_data]
            
#         messages = [{"role": "system", "content": sys_prompt}] + history + [user_msg]
        
#         # URL DÃ¼zeltme (/api/chat endpoint'i zorunlu)
#         ollama_url = Config.OLLAMA_URL
#         if "/api/" not in ollama_url:
#             ollama_url = f"{ollama_url.rstrip('/')}/api/chat"
        
#         # 3. Ä°STEK GÃ–NDERÄ°MÄ°
#         for attempt in range(2):
#             try:
#                 async with aiohttp.ClientSession() as session:
#                     async with session.post(
#                         ollama_url,
#                         json={
#                             "model": model,
#                             "messages": messages,
#                             "stream": False,
#                             "options": {"temperature": 0.7}
#                         },
#                         timeout=EngineConfig.OLLAMA_TIMEOUT
#                     ) as response:
                        
#                         if response.status == 200:
#                             data = await response.json()
#                             reply = data.get("message", {}).get("content", "").strip()
                            
#                             # Memory'ye kaydet
#                             if self.memory:
#                                 self.memory.save(agent, "user", user_text)
#                                 self.memory.save(agent, "assistant", reply)
                            
#                             return {"agent": agent, "content": reply}
                        
#                         elif response.status == 404:
#                             return {
#                                 "agent": agent, 
#                                 "content": f"âš ï¸ Model BulunamadÄ±: '{model}'. LÃ¼tfen terminalde `ollama pull {model}` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n."
#                             }
                        
#                         else:
#                             logger.error(f"Ollama ({model}) HatasÄ±: {response.status}")
            
#             except asyncio.TimeoutError:
#                 logger.error("Ollama timeout")
            
#             except Exception as e:
#                 logger.error(f"Ollama baÄŸlantÄ± hatasÄ±: {e}")
            
#             if attempt == 0:
#                 await asyncio.sleep(2)
        
#         # TÃ¼m denemeler baÅŸarÄ±sÄ±z
#         return {
#             "agent": agent,
#             "content": (
#                 f"LotusAI yerel sunucusu (Ollama - {model}) ÅŸu an kapalÄ± veya yanÄ±t vermiyor. "
#                 "Terminal'de 'ollama serve' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n."
#             )
#         }